{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RNN to generate tweets, using character level generation. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RNN, Softmax, Flatten, Dropout, Input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Load_Tweets/data/tweet_data.csv\") # this will break if this file is moved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the tweets into one string.\n",
    "\n",
    "tweet_txt = data['TEXT'][:].str.cat(sep=' ')\n",
    "len(tweet_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, let's check out one of these tweets.\n",
    "\n",
    "print(tweet_txt[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique characters used.\n",
    "\n",
    "chars = list(set(tweet_txt))\n",
    "chars.sort()\n",
    "print(\"Number of unique characters: \", len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a character mapping.\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(chars))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to cut the data into overlapping sequences of characters.\n",
    "# Tweets have a max length of 150 but we want to understand how to write a \n",
    "# tweet so we should pick a length smaller that that. Let's choose a random number, \n",
    "# how about 30.\n",
    "\n",
    "# maxlen -> the maximum character length each input will be before we \n",
    "#           predict the next character.\n",
    "#\n",
    "# step -> The jump we make till we start our next group. For example\n",
    "#         If our list what [a, d, c, r, r, e, y, d, d ,s], with a maxlen\n",
    "#         of 3 and step of 2, then we would have lists, [a, d, c], [c, r, r]\n",
    "#         [r, r, e], and so on.\n",
    "#\n",
    "# sentences -> a list of the character strings of length maxlen\n",
    "#\n",
    "# next_char -> a list of the next characters to be predicted. i.e. after t  30 characters\n",
    "#              have been placed in the model, it should predict the 31st character.\n",
    "\n",
    "\n",
    "maxlen = 30\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(tweet_txt) - maxlen, step):\n",
    "    sentences.append(tweet_txt[i:i + maxlen])\n",
    "    next_chars.append(tweet_txt[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to make a 3-dimensional array that has the shape\n",
    "# (len(sentences), maxlen, len(chars)) a small example matrix might look like this:\n",
    "#\n",
    "#       shape (3, 4, 4)\n",
    "#\n",
    "#            / 0 1 0 0 /\n",
    "#           / 1 0 1 0 /\n",
    "#          / 0 0 0 1 /    Level 1.\n",
    "#         / 1 2 3 4 / \n",
    "\n",
    "#          -------------\n",
    "\n",
    "#            / 1 0 0 0 /\n",
    "#           / 0 0 1 0 /\n",
    "#          / 0 1 0 1 /    Level 2.\n",
    "#         / 1 2 3 4 /  \n",
    "\n",
    "#          -------------\n",
    "\n",
    "#            / 0 0 1 0 /\n",
    "#           / 1 0 0 1 /\n",
    "#          / 0 1 0 0 /    Level 3.\n",
    "#         / 1 2 3 4 / \n",
    "\n",
    "\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_chars[i]]] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here we define the model, and compile it.\n",
    "\n",
    "\"\"\" Here is the model\n",
    "\n",
    "        --------- LSTM ----------\n",
    "           |        |       |    \n",
    "          \\ /      \\ /     \\ / \n",
    "        --------- Dropuot -------\n",
    "           |        |       |    \n",
    "          \\ /      \\ /     \\ /\n",
    "        --------- LSTM ----------\n",
    "           |        |       |    \n",
    "          \\ /      \\ /     \\ / \n",
    "        --------- Dropout -------\n",
    "           |        |       |    \n",
    "          \\ /      \\ /     \\ /\n",
    "        --------- DENSE ----------\n",
    "\"\"\"\n",
    "        \n",
    "model=Sequential()\n",
    "\n",
    "shape = (maxlen, len(chars))\n",
    "model.add(LSTM(128, input_shape=shape, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(128, input_shape=shape))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(chars), activation=\"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()\n",
    "print()\n",
    "print(\"---------------\")\n",
    "print(\"Data Dimensions\")\n",
    "print(\"---------------\")\n",
    "print(\"X: \", X.shape)\n",
    "print(\"y: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It should be mentioned that this code is not my own, it is used for testing purposes, and does not\n",
    "# reflect the groups code base.\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(tweet_txt) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = tweet_txt[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = index_to_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(X, y, \n",
    "          batch_size=100000,\n",
    "          epochs=50,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our model trained, let's see how well it was able to predict.\n",
    "# Here I will give it a starting string of 30 characters long, randomly chosen from \n",
    "# the entirety of the tweet texts, and we will see what it outputs! This is exciting!!\n",
    "# We will start by producing one tweet, which is 150 characters long.\n",
    "\n",
    "\n",
    "start_index = random.randint(0, len(tweet_txt) - maxlen - 1)\n",
    "starter =  tweet_txt[start_index : start_index + 30]\n",
    "generated = starter\n",
    "\n",
    "# x_pred = np.zeros((1, maxlen, len(chars)), dtype=np.bool)\n",
    "# for t, char in enumerate(starter):\n",
    "#     x_pred[0, t, char_to_index[char]] = 1\n",
    "\n",
    "# y_hat = model.predict(x_pred)[0]\n",
    "\n",
    "# y_hat\n",
    "for i in range(0, 120):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)), dtype=np.bool)\n",
    "    for t, char in enumerate(starter):\n",
    "        x_pred[0, t, char_to_index[char]] = 1\n",
    "        \n",
    "    pred = model.predict(x_pred)[0]\n",
    "    next_index = sample(pred)\n",
    "    next_char = index_to_char[next_index]\n",
    "    \n",
    "    generated += next_char\n",
    "    starter = starter[1:] + next_char\n",
    "    \n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we save the model\n",
    "\n",
    "save.model('first_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
