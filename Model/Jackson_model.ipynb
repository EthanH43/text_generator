{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RNN to generate tweets, using character level generation. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RNN, Softmax, Flatten, Dropout, Input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(inpt, maxlen=30, step=3):\n",
    "    \"\"\" Build data from String to list of characters.\n",
    "\n",
    "    Here we cut the data into overlapping sequences of characters.\n",
    "    Tweets have a max length of 150 but we want to understand how to write a \n",
    "    tweet so we should pick a length smaller that that. Let's choose a random number, \n",
    "    how about 30.\n",
    "                 \n",
    "    -----------\n",
    "    Args:\n",
    "    -----------\n",
    "    \n",
    "        inpt -> String of text\n",
    "\n",
    "        maxlen -> the maximum character length each input will be before we \n",
    "                  predict the next character.\n",
    "\n",
    "        step -> The jump we make till we start our next group. For example\n",
    "                If our list what [a, d, c, r, r, e, y, d, d ,s], with a maxlen\n",
    "                of 3 and step of 2, then we would have lists, [a, d, c], [c, r, r]\n",
    "                [r, r, e], and so on.\n",
    "                \n",
    "    -----------\n",
    "    Returns:\n",
    "    -----------\n",
    "        \n",
    "        Tuple of 2 elements -> (sentences, next_char)\n",
    "    \n",
    "        sentences -> a list of the character strings of length maxlen\n",
    "\n",
    "        next_char -> a list of the next characters to be predicted. i.e. after t  30 characters\n",
    "                 have been placed in the model, it should predict the 31st character.\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(tweet_txt) - maxlen, step):\n",
    "        sentences.append(tweet_txt[i:i + maxlen])\n",
    "        next_chars.append(tweet_txt[i + maxlen])\n",
    "    \n",
    "    return sentences, next_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_array(sentences, next_chars, test_size=0.20):\n",
    "    \"\"\" Build data from lists to numpy vectors.\n",
    "    \n",
    "    We want to make a 3-dimensional array that has the shape\n",
    "    (len(sentences), maxlen, len(chars)) a small example matrix might look like this:\n",
    "\n",
    "          shape (3, 4, 4)\n",
    "\n",
    "               / 0 1 0 0 /\n",
    "              / 1 0 1 0 /\n",
    "             / 0 0 0 1 /    Level 1.\n",
    "            / 1 2 3 4 / \n",
    "\n",
    "             -------------\n",
    "\n",
    "               / 1 0 0 0 /\n",
    "              / 0 0 1 0 /\n",
    "             / 0 1 0 1 /    Level 2.\n",
    "            / 1 2 3 4 /  \n",
    "\n",
    "             -------------\n",
    "\n",
    "               / 0 0 1 0 /\n",
    "              / 1 0 0 1 /\n",
    "             / 0 1 0 0 /    Level 3.\n",
    "            / 1 2 3 4 /                  \n",
    "\n",
    "\n",
    "    -----------\n",
    "    Args:\n",
    "    -----------\n",
    "    \n",
    "        sentences -> a list of the character strings of length maxlen\n",
    "\n",
    "        next_char -> a list of the next characters to be predicted. i.e. after t  30 characters\n",
    "                     have been placed in the model, it should predict the 31st character.\n",
    "                \n",
    "        test_size ->  A number between 0 and 1 that represents the percentage of data that \n",
    "                      should be set aside to train on.\n",
    "                \n",
    "    -----------\n",
    "    Returns:\n",
    "    -----------\n",
    "        \n",
    "        Tuple of 4 elements - X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, char_to_index[char]] = 1\n",
    "            y[i, char_to_index[next_chars[i]]] = 1 \n",
    "            \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "            \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this cell is copied from A Keras example file available on github.\n",
    "# Reference: https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    f = open('twitter_epoch_test.log', 'a')\n",
    "    \n",
    "    start_index = random.randint(0, len(tweet_txt) - maxlen - 1)\n",
    "    f.write('\\n')\n",
    "    f.write('----- Generating text after Epoch: %d\\n' % epoch)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('---- Generating text to file: twitter_epoch_test.log ----')\n",
    "        print('---- with diversity: %f\\n' % diversity)\n",
    "        f.write('----- diversity: %f\\n' % diversity)\n",
    "\n",
    "\n",
    "        generated = ''\n",
    "        sentence = tweet_txt[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        f.write('----- Generating with seed: \"' + sentence + '\"\\n')\n",
    "        f.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = index_to_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            f.write(next_char)\n",
    "            f.flush()\n",
    "        f.write('\\n\\n')\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RETWEET</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>786204978629185536</td>\n",
       "      <td>False</td>\n",
       "      <td>PAY TO PLAY POLITICS. #CrookedHillary [URL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>786201435486781440</td>\n",
       "      <td>False</td>\n",
       "      <td>Very little pick-up by the dishonest media of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>786189446274248704</td>\n",
       "      <td>False</td>\n",
       "      <td>Crooked Hillary Clinton likes to talk about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>786054986534969344</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you Florida- a MOVEMENT that has never b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>786007502639038464</td>\n",
       "      <td>False</td>\n",
       "      <td>Join me Thursday in Florida &amp;amp; Ohio!West Pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  RETWEET  \\\n",
       "0  786204978629185536    False   \n",
       "1  786201435486781440    False   \n",
       "2  786189446274248704    False   \n",
       "3  786054986534969344    False   \n",
       "4  786007502639038464    False   \n",
       "\n",
       "                                                TEXT  \n",
       "0        PAY TO PLAY POLITICS. #CrookedHillary [URL]  \n",
       "1  Very little pick-up by the dishonest media of ...  \n",
       "2  Crooked Hillary Clinton likes to talk about th...  \n",
       "3  Thank you Florida- a MOVEMENT that has never b...  \n",
       "4  Join me Thursday in Florida &amp; Ohio!West Pa...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Load_Tweets/data/tweet_data.csv\") # this will break if this file is moved!\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10622.000000\n",
       "mean       141.512709\n",
       "std         70.206293\n",
       "min          5.000000\n",
       "25%         99.000000\n",
       "50%        135.000000\n",
       "75%        150.000000\n",
       "max        315.000000\n",
       "Name: TEXT, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TEXT'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1513769"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all the tweets into one string\n",
    "\n",
    "tweet_txt = data['TEXT'][:].str.cat(sep=' ')\n",
    "len(tweet_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters:  369\n"
     ]
    }
   ],
   "source": [
    "# Get all the unique characters used, and make a character mapping. \n",
    "# Here we set Global Variables that are used throughout the code.\n",
    "\n",
    "chars = list(set(tweet_txt))\n",
    "chars.sort()\n",
    "char_to_index = dict((c, i) for i, c in enumerate(chars))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print(\"Number of unique characters: \", len(chars))\n",
    "maxlen = 141 # Chosen because the average length of a tweet in our data is 141 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of unedited twitter tweets.\n",
    "tweets_lst = []\n",
    "path = '/Users/schuylerjackson/text_generator/Load_Tweets/data/tweet_data.csv'\n",
    "with open(path) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        tweets_lst.append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a dictionary to dump into a file.\n",
    "pass_data_to_web = {\n",
    "    'tweets_lst': tweets_lst,\n",
    "    'chars': chars,\n",
    "    'char_to_index': char_to_index,\n",
    "    'index_to_char': index_to_char,\n",
    "    'maxlen': maxlen\n",
    "}\n",
    "pass_data_to_web['maxlen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a file that can be loaded into the website framework.\n",
    "# dump into file\n",
    "\n",
    "with open('/Users/schuylerjackson/text_generator/website/flask_site/data/model.data', 'wb') as file:\n",
    "    pickle.dump(pass_data_to_web, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "\ttrain: (80727, 141, 369)\n",
      "\ttest: (20182, 141, 369)\n",
      "Target:\n",
      "\ttrain: (80727, 369)\n",
      "\ttest: (20182, 369)\n"
     ]
    }
   ],
   "source": [
    "# Here we actual build the data.\n",
    "\n",
    "sentences, next_chars = build_data(inpt=tweet_txt, maxlen=maxlen, step=15)\n",
    "X_train, X_test, y_train, y_test = build_array(sentences, next_chars, test_size=0.20)\n",
    "print(\"Data:\\n\\ttrain: {}\\n\\ttest: {}\".format(X_train.shape, X_test.shape))\n",
    "print(\"Target:\\n\\ttrain: {}\\n\\ttest: {}\".format(y_train.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 141)               288204    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 141)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 369)               52398     \n",
      "=================================================================\n",
      "Total params: 340,602\n",
      "Trainable params: 340,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "---------------\n",
      "Data Dimensions\n",
      "---------------\n",
      "X:  (80727, 141, 369)\n",
      "y:  (80727, 369)\n"
     ]
    }
   ],
   "source": [
    "# # Here we define the model, and compile it.\n",
    "        \n",
    "model=Sequential()\n",
    "\n",
    "shape = (maxlen, len(chars))\n",
    "# model.add(LSTM(128, input_shape=shape, return_sequences=True))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# The average length of a tweet is 141 characters so that is the number I will choose.\n",
    "model.add(LSTM(units=141, input_shape=shape))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(chars), activation=\"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "model.summary()\n",
    "print()\n",
    "print(\"---------------\")\n",
    "print(\"Data Dimensions\")\n",
    "print(\"---------------\")\n",
    "print(\"X: \", X_train.shape)\n",
    "print(\"y: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "80000/80727 [============================>.] - ETA: 0s - loss: 3.3238 - acc: 0.1776\n",
      "---- Generating text to file: twitter_epoch_test.log ----\n",
      "---- with diversity: 0.200000\n",
      "\n",
      "\n",
      "---- Generating text to file: twitter_epoch_test.log ----\n",
      "---- with diversity: 0.500000\n",
      "\n",
      "\n",
      "---- Generating text to file: twitter_epoch_test.log ----\n",
      "---- with diversity: 1.000000\n",
      "\n",
      "\n",
      "---- Generating text to file: twitter_epoch_test.log ----\n",
      "---- with diversity: 1.200000\n",
      "\n",
      "80727/80727 [==============================] - 289s 4ms/sample - loss: 3.3202 - acc: 0.1781\n",
      "Epoch 2/2\n",
      "80000/80727 [============================>.] - ETA: 0s - loss: 2.6109 - acc: 0.3013\n",
      "---- Generating text to file: twitter_epoch_test.log ----\n",
      "---- with diversity: 0.200000\n",
      "\n",
      "\n",
      "---- Generating text to file: twitter_epoch_test.log ----\n",
      "---- with diversity: 0.500000\n",
      "\n",
      "\n",
      "---- Generating text to file: twitter_epoch_test.log ----\n",
      "---- with diversity: 1.000000\n",
      "\n",
      "\n",
      "---- Generating text to file: twitter_epoch_test.log ----\n",
      "---- with diversity: 1.200000\n",
      "\n",
      "80727/80727 [==============================] - 289s 4ms/sample - loss: 2.6092 - acc: 0.3016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f7ca3c2e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=1000,\n",
    "          epochs=2,\n",
    "          callbacks=[print_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalutate the model\n",
    "\n",
    "cross_entropy_loss, accuracy = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ting to the White House.”  So pledited him #Aaller' Shutd down does before concorined tusnNes &amp; calldoel as wish the great also for '@CTRJud’ slat\n"
     ]
    }
   ],
   "source": [
    "# Now that we have our model trained, let's see how well it was able to predict.\n",
    "# Here I will give it a starting string of 30 characters long, randomly chosen from \n",
    "# the entirety of the tweet texts, and we will see what it outputs! This is exciting!!\n",
    "# We will start by producing one tweet, which is 150 characters long.\n",
    "\n",
    "\n",
    "start_index = random.randint(0, len(tweet_txt) - maxlen - 1)\n",
    "starter =  tweet_txt[start_index : start_index + 30]\n",
    "# starter = \"Hillary is a bad actor\"\n",
    "generated = starter\n",
    "\n",
    "# x_pred = np.zeros((1, maxlen, len(chars)), dtype=np.bool)\n",
    "# for t, char in enumerate(starter):\n",
    "#     x_pred[0, t, char_to_index[char]] = 1\n",
    "\n",
    "# y_hat = model.predict(x_pred)[0]\n",
    "\n",
    "# y_hat\n",
    "for i in range(0, 120):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)), dtype=np.bool)\n",
    "    for t, char in enumerate(starter):\n",
    "        x_pred[0, t, char_to_index[char]] = 1\n",
    "        \n",
    "    pred = model.predict(x_pred)[0]\n",
    "    next_index = sample(pred)\n",
    "    next_char = index_to_char[next_index]\n",
    "    \n",
    "    generated += next_char\n",
    "    starter = starter[1:] + next_char\n",
    "    \n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-02ba09826edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here we save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save' is not defined"
     ]
    }
   ],
   "source": [
    "# Here we save the model\n",
    "\n",
    "save.model('first_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" HERE I AM DOING SOME MODEL TESTING \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/schuylerjackson/anaconda3/envs/data100/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/schuylerjackson/anaconda3/envs/data100/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/schuylerjackson/anaconda3/envs/data100/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../Saved_models/first_char_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504580/504580 [==============================] - 211s 418us/sample - loss: 1.4642 - acc: 0.6004\n"
     ]
    }
   ],
   "source": [
    "cross_entropy_loss, accuracy = model.evaluate(X, y, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
