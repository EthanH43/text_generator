{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RNN to generate tweets, using character level generation. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RNN, Softmax, Flatten, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Load_Tweets/data/tweet_data.csv\") # this will break if this file is moved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RETWEET</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>786204978629185536</td>\n",
       "      <td>False</td>\n",
       "      <td>PAY TO PLAY POLITICS. #CrookedHillary [URL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>786201435486781440</td>\n",
       "      <td>False</td>\n",
       "      <td>Very little pick-up by the dishonest media of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>786189446274248704</td>\n",
       "      <td>False</td>\n",
       "      <td>Crooked Hillary Clinton likes to talk about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>786054986534969344</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you Florida- a MOVEMENT that has never b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>786007502639038464</td>\n",
       "      <td>False</td>\n",
       "      <td>Join me Thursday in Florida &amp;amp; Ohio!West Pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  RETWEET  \\\n",
       "0  786204978629185536    False   \n",
       "1  786201435486781440    False   \n",
       "2  786189446274248704    False   \n",
       "3  786054986534969344    False   \n",
       "4  786007502639038464    False   \n",
       "\n",
       "                                                TEXT  \n",
       "0        PAY TO PLAY POLITICS. #CrookedHillary [URL]  \n",
       "1  Very little pick-up by the dishonest media of ...  \n",
       "2  Crooked Hillary Clinton likes to talk about th...  \n",
       "3  Thank you Florida- a MOVEMENT that has never b...  \n",
       "4  Join me Thursday in Florida &amp; Ohio!West Pa...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the tweets into one string.\n",
    "\n",
    "tweet_txt = data['TEXT'].str.cat(sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAY TO PLAY POLITICS. #CrookedHillary [URL] Very little pick-up by the dishonest media of incredible information provided by WikiLeaks. So dishonest! \n"
     ]
    }
   ],
   "source": [
    "# Ok, let's check out one of these tweets.\n",
    "\n",
    "print(tweet_txt[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters:  369\n"
     ]
    }
   ],
   "source": [
    "# Get all the unique characters used.\n",
    "\n",
    "char = list(set(tweet_txt))\n",
    "char.sort()\n",
    "print(\"Number of unique characters: \", len(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a character mapping.\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(char))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '#': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " '&': 6,\n",
       " \"'\": 7,\n",
       " '(': 8,\n",
       " ')': 9,\n",
       " '*': 10,\n",
       " '+': 11,\n",
       " ',': 12,\n",
       " '-': 13,\n",
       " '.': 14,\n",
       " '/': 15,\n",
       " '0': 16,\n",
       " '1': 17,\n",
       " '2': 18,\n",
       " '3': 19,\n",
       " '4': 20,\n",
       " '5': 21,\n",
       " '6': 22,\n",
       " '7': 23,\n",
       " '8': 24,\n",
       " '9': 25,\n",
       " ':': 26,\n",
       " ';': 27,\n",
       " '=': 28,\n",
       " '?': 29,\n",
       " '@': 30,\n",
       " 'A': 31,\n",
       " 'B': 32,\n",
       " 'C': 33,\n",
       " 'D': 34,\n",
       " 'E': 35,\n",
       " 'F': 36,\n",
       " 'G': 37,\n",
       " 'H': 38,\n",
       " 'I': 39,\n",
       " 'J': 40,\n",
       " 'K': 41,\n",
       " 'L': 42,\n",
       " 'M': 43,\n",
       " 'N': 44,\n",
       " 'O': 45,\n",
       " 'P': 46,\n",
       " 'Q': 47,\n",
       " 'R': 48,\n",
       " 'S': 49,\n",
       " 'T': 50,\n",
       " 'U': 51,\n",
       " 'V': 52,\n",
       " 'W': 53,\n",
       " 'X': 54,\n",
       " 'Y': 55,\n",
       " 'Z': 56,\n",
       " '[': 57,\n",
       " '\\\\': 58,\n",
       " ']': 59,\n",
       " '_': 60,\n",
       " 'a': 61,\n",
       " 'b': 62,\n",
       " 'c': 63,\n",
       " 'd': 64,\n",
       " 'e': 65,\n",
       " 'f': 66,\n",
       " 'g': 67,\n",
       " 'h': 68,\n",
       " 'i': 69,\n",
       " 'j': 70,\n",
       " 'k': 71,\n",
       " 'l': 72,\n",
       " 'm': 73,\n",
       " 'n': 74,\n",
       " 'o': 75,\n",
       " 'p': 76,\n",
       " 'q': 77,\n",
       " 'r': 78,\n",
       " 's': 79,\n",
       " 't': 80,\n",
       " 'u': 81,\n",
       " 'v': 82,\n",
       " 'w': 83,\n",
       " 'x': 84,\n",
       " 'y': 85,\n",
       " 'z': 86,\n",
       " '{': 87,\n",
       " '|': 88,\n",
       " '}': 89,\n",
       " '~': 90,\n",
       " '\\xa0': 91,\n",
       " '¯': 92,\n",
       " 'É': 93,\n",
       " 'á': 94,\n",
       " 'â': 95,\n",
       " 'é': 96,\n",
       " 'í': 97,\n",
       " 'ñ': 98,\n",
       " 'ó': 99,\n",
       " 'ø': 100,\n",
       " 'ú': 101,\n",
       " 'ğ': 102,\n",
       " 'ĺ': 103,\n",
       " 'ō': 104,\n",
       " 'ד': 105,\n",
       " 'ז': 106,\n",
       " 'ח': 107,\n",
       " 'י': 108,\n",
       " 'ם': 109,\n",
       " 'מ': 110,\n",
       " 'ק': 111,\n",
       " 'ת': 112,\n",
       " 'آ': 113,\n",
       " 'ا': 114,\n",
       " 'ب': 115,\n",
       " 'ت': 116,\n",
       " 'ج': 117,\n",
       " 'د': 118,\n",
       " 'ر': 119,\n",
       " 'س': 120,\n",
       " 'ش': 121,\n",
       " 'ط': 122,\n",
       " 'ف': 123,\n",
       " 'ق': 124,\n",
       " 'ل': 125,\n",
       " 'م': 126,\n",
       " 'ن': 127,\n",
       " 'ه': 128,\n",
       " 'و': 129,\n",
       " 'چ': 130,\n",
       " 'ژ': 131,\n",
       " 'ک': 132,\n",
       " 'ی': 133,\n",
       " '۰': 134,\n",
       " '۴': 135,\n",
       " 'ễ': 136,\n",
       " '–': 137,\n",
       " '—': 138,\n",
       " '‘': 139,\n",
       " '’': 140,\n",
       " '“': 141,\n",
       " '”': 142,\n",
       " '•': 143,\n",
       " '…': 144,\n",
       " '\\u2066': 145,\n",
       " '\\u2069': 146,\n",
       " '↔': 147,\n",
       " '☀': 148,\n",
       " '☉': 149,\n",
       " '☑': 150,\n",
       " '☘': 151,\n",
       " '⚠': 152,\n",
       " '⚡': 153,\n",
       " '⚾': 154,\n",
       " '✅': 155,\n",
       " '✈': 156,\n",
       " '✔': 157,\n",
       " '❌': 158,\n",
       " '❤': 159,\n",
       " '➜': 160,\n",
       " '➡': 161,\n",
       " '⬇': 162,\n",
       " '、': 163,\n",
       " '。': 164,\n",
       " '「': 165,\n",
       " '」': 166,\n",
       " 'あ': 167,\n",
       " 'い': 168,\n",
       " 'う': 169,\n",
       " 'お': 170,\n",
       " 'か': 171,\n",
       " 'が': 172,\n",
       " 'き': 173,\n",
       " 'ぎ': 174,\n",
       " 'く': 175,\n",
       " 'げ': 176,\n",
       " 'こ': 177,\n",
       " 'ご': 178,\n",
       " 'さ': 179,\n",
       " 'ざ': 180,\n",
       " 'し': 181,\n",
       " 'す': 182,\n",
       " 'せ': 183,\n",
       " 'そ': 184,\n",
       " 'た': 185,\n",
       " 'っ': 186,\n",
       " 'て': 187,\n",
       " 'で': 188,\n",
       " 'と': 189,\n",
       " 'な': 190,\n",
       " 'に': 191,\n",
       " 'の': 192,\n",
       " 'は': 193,\n",
       " 'ま': 194,\n",
       " 'み': 195,\n",
       " 'め': 196,\n",
       " 'や': 197,\n",
       " 'よ': 198,\n",
       " 'り': 199,\n",
       " 'る': 200,\n",
       " 'れ': 201,\n",
       " 'を': 202,\n",
       " 'ア': 203,\n",
       " 'ィ': 204,\n",
       " 'イ': 205,\n",
       " 'サ': 206,\n",
       " 'ジ': 207,\n",
       " 'ス': 208,\n",
       " 'ゼ': 209,\n",
       " 'ダ': 210,\n",
       " 'チ': 211,\n",
       " 'ッ': 212,\n",
       " 'ツ': 213,\n",
       " 'デ': 214,\n",
       " 'ト': 215,\n",
       " 'ド': 216,\n",
       " 'ナ': 217,\n",
       " 'フ': 218,\n",
       " 'プ': 219,\n",
       " 'ベ': 220,\n",
       " 'ミ': 221,\n",
       " 'モ': 222,\n",
       " 'ラ': 223,\n",
       " 'リ': 224,\n",
       " 'ル': 225,\n",
       " 'ロ': 226,\n",
       " 'ン': 227,\n",
       " '一': 228,\n",
       " '三': 229,\n",
       " '上': 230,\n",
       " '世': 231,\n",
       " '今': 232,\n",
       " '会': 233,\n",
       " '共': 234,\n",
       " '初': 235,\n",
       " '到': 236,\n",
       " '功': 237,\n",
       " '北': 238,\n",
       " '半': 239,\n",
       " '印': 240,\n",
       " '取': 241,\n",
       " '史': 242,\n",
       " '同': 243,\n",
       " '向': 244,\n",
       " '問': 245,\n",
       " '善': 246,\n",
       " '国': 247,\n",
       " '大': 248,\n",
       " '太': 249,\n",
       " '密': 250,\n",
       " '尽': 251,\n",
       " '常': 252,\n",
       " '幕': 253,\n",
       " '平': 254,\n",
       " '当': 255,\n",
       " '成': 256,\n",
       " '拉': 257,\n",
       " '揺': 258,\n",
       " '携': 259,\n",
       " '日': 260,\n",
       " '早': 261,\n",
       " '最': 262,\n",
       " '朝': 263,\n",
       " '本': 264,\n",
       " '来': 265,\n",
       " '標': 266,\n",
       " '機': 267,\n",
       " '歴': 268,\n",
       " '洋': 269,\n",
       " '活': 270,\n",
       " '点': 271,\n",
       " '由': 272,\n",
       " '界': 273,\n",
       " '的': 274,\n",
       " '盟': 275,\n",
       " '目': 276,\n",
       " '相': 277,\n",
       " '着': 278,\n",
       " '示': 279,\n",
       " '祈': 280,\n",
       " '米': 281,\n",
       " '絆': 282,\n",
       " '統': 283,\n",
       " '緊': 284,\n",
       " '脳': 285,\n",
       " '臨': 286,\n",
       " '自': 287,\n",
       " '致': 288,\n",
       " '行': 289,\n",
       " '要': 290,\n",
       " '訪': 291,\n",
       " '認': 292,\n",
       " '談': 293,\n",
       " '識': 294,\n",
       " '費': 295,\n",
       " '通': 296,\n",
       " '速': 297,\n",
       " '連': 298,\n",
       " '違': 299,\n",
       " '重': 300,\n",
       " '開': 301,\n",
       " '間': 302,\n",
       " '非': 303,\n",
       " '領': 304,\n",
       " '題': 305,\n",
       " '首': 306,\n",
       " '鮮': 307,\n",
       " '️': 308,\n",
       " '０': 309,\n",
       " '２': 310,\n",
       " 'Ｇ': 311,\n",
       " '🇦': 312,\n",
       " '🇧': 313,\n",
       " '🇨': 314,\n",
       " '🇪': 315,\n",
       " '🇫': 316,\n",
       " '🇬': 317,\n",
       " '🇭': 318,\n",
       " '🇮': 319,\n",
       " '🇯': 320,\n",
       " '🇰': 321,\n",
       " '🇱': 322,\n",
       " '🇲': 323,\n",
       " '🇳': 324,\n",
       " '🇴': 325,\n",
       " '🇵': 326,\n",
       " '🇷': 327,\n",
       " '🇸': 328,\n",
       " '🇹': 329,\n",
       " '🇺': 330,\n",
       " '🇻': 331,\n",
       " '🇼': 332,\n",
       " '🇽': 333,\n",
       " '🌺': 334,\n",
       " '🎄': 335,\n",
       " '🎥': 336,\n",
       " '🏆': 337,\n",
       " '🏈': 338,\n",
       " '🏛': 339,\n",
       " '🏻': 340,\n",
       " '🐶': 341,\n",
       " '👉': 342,\n",
       " '👍': 343,\n",
       " '👎': 344,\n",
       " '👏': 345,\n",
       " '👿': 346,\n",
       " '💕': 347,\n",
       " '💜': 348,\n",
       " '💨': 349,\n",
       " '💪': 350,\n",
       " '💯': 351,\n",
       " '💰': 352,\n",
       " '📈': 353,\n",
       " '📉': 354,\n",
       " '📱': 355,\n",
       " '📸': 356,\n",
       " '🔟': 357,\n",
       " '🔥': 358,\n",
       " '🔹': 359,\n",
       " '🗽': 360,\n",
       " '🚁': 361,\n",
       " '🚂': 362,\n",
       " '🚤': 363,\n",
       " '🚨': 364,\n",
       " '🤔': 365,\n",
       " '🤖': 366,\n",
       " '🦃': 367,\n",
       " '\\U0010fc00': 368}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maxlen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d7781a691efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# e=Embedding(total_words, EMBEDDING_DIM, weights=[embedding_matrix],input_length=maxlen,trainable=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# model.add(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# model.add(Dropout(0.1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# model.add(Flatten())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'maxlen' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# embedding_layer= Embedding(total_words, EMBEDDING_DIM, weights=[embedding_matrix],input_length=max_seq,trainable=False)\n",
    "# sequence_input = Input(shape=(max_seq,), dtype='int32')\n",
    "# embedded_sequences= embedding_layer(sequence_input)\n",
    "model=Sequential()\n",
    "# e=Embedding(total_words, EMBEDDING_DIM, weights=[embedding_matrix],input_length=maxlen,trainable=False)\n",
    "# model.add(e)\n",
    "model.add(LSTM(100, input_shape=(maxlen, EMBEDDING_DIM)))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(total_words, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
