{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out list words and the apostrophe situation in the step for loop\n",
    "# check out allowing more than maxseqlen in generate text\n",
    "# look into batch size\n",
    "#text generation apostrpphe breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import optimizers\n",
    "import sys\n",
    "from keras.callbacks import LambdaCallback\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, numb_next_words):\n",
    "    output=seed_text\n",
    "    for i in range (numb_next_words):\n",
    "        \n",
    "        words_gen = set(seed_text.split())\n",
    "        words_gen=list(words_gen) #create list of unique words in seed text\n",
    "        \n",
    "        \n",
    "#         for i in range (len(words_gen)): #replace all ' in seed text\n",
    "#             words_gen[i]=words_gen[i].replace(\"‘\", '').replace(\"’\", '').replace(\"'\", '')\n",
    "            \n",
    "        #create a dictionary with index and word\n",
    "        word_indices_gen = dict((c, i) for i, c in enumerate(words_gen, 1)) \n",
    "        \n",
    "       #turn sentence into a sequence of numbers\n",
    "        sequence=[] \n",
    "        for word in seed_text.split():\n",
    "            sequence.append(word_indices_gen[word])\n",
    "        sequence_padded = pad_sequences([sequence], maxlen=10, padding='pre')\n",
    "#         sequence_padded=sequence\n",
    "            \n",
    "        #create an embedding matrix with same indices as word_index \n",
    "        EMBEDDING_DIM=25\n",
    "        total_words=len(word_indices_gen)+1\n",
    "        embedding_matrix = np.zeros((total_words, EMBEDDING_DIM))\n",
    "        for word, i in word_indices_gen.items():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        #create X input with embedding matrix for specific words (by their index)\n",
    "        gener=[]\n",
    "        for number in sequence_padded:\n",
    "            gener.append(embedding_matrix[number])\n",
    "\n",
    "        predicted=model.predict([gener], verbose=0)\n",
    "\n",
    "        predicted=sample(predicted[0])\n",
    "        output_word=\"\"\n",
    "        for word, index in word_indices.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        output+=\" \" + output_word\n",
    "        seed_text+=\" \" + output_word\n",
    "        seed_text=seed_text.split(' ', 1)[1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(listofwords) - maxlen - 1)\n",
    "    for diversity in [0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = listofwords[start_index: start_index + maxlen].str.cat(sep=' ')\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generate_text(generated, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data=pd.read_csv('../Load_Tweets/data/tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = tweet_data['TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_all = tweet_data['TEXT'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofwords=pd.Series(tweet_text_all.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          PAY TO PLAY POLITICS. #CrookedHillary [URL]\n",
       "1    Very little pick-up by the dishonest media of ...\n",
       "2    Crooked Hillary Clinton likes to talk about th...\n",
       "3    Thank you Florida- a MOVEMENT that has never b...\n",
       "4    Join me Thursday in Florida &amp; Ohio!West Pa...\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc10cabf518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_words=listofwords.value_counts()\n",
    "top_words_percent= top_words/len(listofwords)\n",
    "top_words.head(50).plot.bar()\n",
    "# top_words.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250988"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_chars=len(tweet_text_all)\n",
    "total_chars\n",
    "total_wordz=len((tweet_text_all.split()))\n",
    "total_wordz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique words 32293\n",
      "total number of unique chars 369\n"
     ]
    }
   ],
   "source": [
    "chars = set(tweet_text_all)\n",
    "words = set(tweet_text_all.split())\n",
    "print (\"total number of unique words\", len(words))\n",
    "print (\"total number of unique chars\", len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace apostrophes in dictionary keys \n",
    "for i in range (len(words)):\n",
    "    words[i]=words[i].replace(\"‘\", '').replace(\"’\", '').replace(\"'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31907"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=set(words)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create forward and reverse word index\n",
    "word_indices = dict((c, i) for i, c in enumerate(words, 1))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words,1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31907"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_indices)\n",
    "max(word_indices.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sentence list: 77465\n",
      "length of next_word list 77465\n"
     ]
    }
   ],
   "source": [
    "#choose step \n",
    "\n",
    "maxlen = 10\n",
    "step = 2\n",
    "\n",
    "sentences = []\n",
    "next_words = []\n",
    "next_words = []\n",
    "list_words = []\n",
    "\n",
    "sentences2 = []\n",
    "for i in range (len(tweet_text)):\n",
    "    list_words = tweet_text.iloc[i].split()\n",
    "    for i in range(len( list_words)):\n",
    "        list_words[i]=list_words[i].replace(\"‘\", '').replace(\"’\", '').replace(\"'\", '')\n",
    "    for i in range(0, len(list_words) - maxlen, step):\n",
    "        sentences2 = ' '.join(list_words[i: i + maxlen])\n",
    "        sentences.append(sentences2)\n",
    "        next_words.append((list_words[i + maxlen]))\n",
    "\n",
    "print ('length of sentence list:', len(sentences))\n",
    "print (\"length of next_word list\", len(next_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=[]\n",
    "y=[]\n",
    "for i, sentence in enumerate(sentences):\n",
    "    sequence=[]\n",
    "    for j, word in enumerate(sentence.split()):\n",
    "        sequence.append(word_indices[word])\n",
    "    sequences.append(sequence)\n",
    "    y.append(word_indices[next_words[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77465, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences=np.asarray(sequences)\n",
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words= len(word_indices)+1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('../word_embeding/glove.twitter.27B.25d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31907"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(word_indices.values())\n",
    "len(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=25\n",
    "embedding_matrix = np.zeros((total_words, EMBEDDING_DIM)) \n",
    "for word, i in word_indices.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31908, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "for number in sequences:\n",
    "    X.append(embedding_matrix[number])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77465, 10, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31908, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31908, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)\n",
    "len(word_indices)\n",
    "len(sentences)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77465,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample=X_train[0:10000]\n",
    "y_train_sample=y_train[0:10000]\n",
    "X_test_sample=X_test[0:1000]\n",
    "y_test_sample=y_test[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20173,\n",
       " 11482,\n",
       " 31488,\n",
       " 31869,\n",
       " 10252,\n",
       " 29202,\n",
       " 8932,\n",
       " 8647,\n",
       " 12440,\n",
       " 26505,\n",
       " 17213,\n",
       " 17014,\n",
       " 29611,\n",
       " 21269,\n",
       " 5024,\n",
       " 9036,\n",
       " 7066,\n",
       " 13486,\n",
       " 17014,\n",
       " 27468,\n",
       " 22726,\n",
       " 26450,\n",
       " 13574,\n",
       " 15360,\n",
       " 14661,\n",
       " 5024,\n",
       " 17213,\n",
       " 19320,\n",
       " 4646,\n",
       " 2532,\n",
       " 5510,\n",
       " 10327,\n",
       " 9180,\n",
       " 258,\n",
       " 733,\n",
       " 17213,\n",
       " 15663,\n",
       " 7444,\n",
       " 17014,\n",
       " 14918,\n",
       " 8876,\n",
       " 12484,\n",
       " 12482,\n",
       " 12605,\n",
       " 11760,\n",
       " 17014,\n",
       " 30322,\n",
       " 8589,\n",
       " 10194,\n",
       " 5510,\n",
       " 14222,\n",
       " 11793,\n",
       " 24517,\n",
       " 8162,\n",
       " 20914,\n",
       " 18189,\n",
       " 14092,\n",
       " 17213,\n",
       " 24683,\n",
       " 1587,\n",
       " 27718,\n",
       " 28931,\n",
       " 17213,\n",
       " 3117,\n",
       " 14092,\n",
       " 1973,\n",
       " 4646,\n",
       " 1258,\n",
       " 17213,\n",
       " 4164,\n",
       " 3585,\n",
       " 15219,\n",
       " 12919,\n",
       " 10514,\n",
       " 27983,\n",
       " 14222,\n",
       " 18860,\n",
       " 20133,\n",
       " 4399,\n",
       " 9726,\n",
       " 3374,\n",
       " 21193,\n",
       " 9036,\n",
       " 5373,\n",
       " 18860,\n",
       " 4164,\n",
       " 24556,\n",
       " 10642,\n",
       " 31797,\n",
       " 17014]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train).shape\n",
    "y_train[10:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               78848     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 31908)             4116132   \n",
      "=================================================================\n",
      "Total params: 4,194,980\n",
      "Trainable params: 4,194,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.regularizers import L1L2\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "# embedding_layer= Embedding(total_words, EMBEDDING_DIM, weights=[embedding_matrix],input_length=max_seq,trainable=False)\n",
    "# sequence_input = Input(shape=(max_seq,), dtype='int32')\n",
    "# embedded_sequences= embedding_layer(sequence_input)\n",
    "model=Sequential()\n",
    "# e=Embedding(total_words, EMBEDDING_DIM, weights=[embedding_matrix],input_length=maxlen,trainable=False)\n",
    "# model.add(e)\n",
    "model.add(LSTM(128, input_shape=(maxlen, EMBEDDING_DIM), bias_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(512, return_sequences=False))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(total_words, activation=\"softmax\"))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "# sgd = optimizers.SGD(lr=0.01, clipvalue=0.5)\n",
    "model.compile(loss='sparse_categorical_crossentropy',  metrics=['accuracy'], optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "# model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "# model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model= load_model(\"../Saved_models/failed_on_99th_epoch_word_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 49577 samples, validate on 12395 samples\n",
      "Epoch 1/10\n",
      "26336/49577 [==============>...............] - ETA: 25s - loss: 8.0414 - acc: 0.0603"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e0f0e8bd0a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=3)\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.900000\n",
      "loss: 9.635607\n",
      "perplexity: 795.4386352619334\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_sample, y_test_sample, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print('loss: %f' % (loss))\n",
    "perplexity = np.exp2(loss)\n",
    "print ('perplexity: {}'.format(perplexity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i will be the U.S. and my great job. and the Dems They We including a big deal with Russia and people\n"
     ]
    }
   ],
   "source": [
    "print (generate_text(\"i will\", 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../failed_on_99th_epoch_word_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10639"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
