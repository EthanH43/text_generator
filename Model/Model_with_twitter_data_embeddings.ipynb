{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out list words and the apostrophe situation in the step for loop\n",
    "# check out allowing more than maxseqlen in generate text\n",
    "# look into batch size\n",
    "#text generation apostrpphe breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import optimizers\n",
    "import sys\n",
    "from keras.callbacks import LambdaCallback\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, numb_next_words):\n",
    "    output=seed_text\n",
    "    for i in range (numb_next_words):\n",
    "        \n",
    "        words_gen = set(seed_text.split())\n",
    "        words_gen=list(words_gen) #create list of unique words in seed text\n",
    "        \n",
    "        \n",
    "#         for i in range (len(words_gen)): #replace all ' in seed text\n",
    "#             words_gen[i]=words_gen[i].replace(\"‘\", '').replace(\"’\", '').replace(\"'\", '')\n",
    "            \n",
    "        #create a dictionary with index and word\n",
    "        word_indices_gen = dict((c, i) for i, c in enumerate(words_gen, 1)) \n",
    "        \n",
    "       #turn sentence into a sequence of numbers\n",
    "        sequence=[] \n",
    "        for word in seed_text.split():\n",
    "            sequence.append(word_indices_gen[word])\n",
    "        sequence_padded = pad_sequences([sequence], maxlen=10, padding='pre')\n",
    "#         sequence_padded=sequence\n",
    "            \n",
    "        #create an embedding matrix with same indices as word_index \n",
    "        EMBEDDING_DIM=25\n",
    "        total_words=len(word_indices_gen)+1\n",
    "        embedding_matrix = np.zeros((total_words, EMBEDDING_DIM))\n",
    "        for word, i in word_indices_gen.items():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        #create X input with embedding matrix for specific words (by their index)\n",
    "        gener=[]\n",
    "        for number in sequence_padded:\n",
    "            gener.append(embedding_matrix[number])\n",
    "\n",
    "        predicted=model.predict([gener], verbose=0)\n",
    "\n",
    "        predicted=sample(predicted[0])\n",
    "        output_word=\"\"\n",
    "        for word, index in word_indices.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        output+=\" \" + output_word\n",
    "        seed_text+=\" \" + output_word\n",
    "        seed_text=seed_text.split(' ', 1)[1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(listofwords) - maxlen - 1)\n",
    "    for diversity in [0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = listofwords[start_index: start_index + maxlen].str.cat(sep=' ')\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generate_text(generated, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data=pd.read_csv('../Load_Tweets/data/tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = tweet_data['TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_all = tweet_data['TEXT'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofwords=pd.Series(tweet_text_all.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          PAY TO PLAY POLITICS. #CrookedHillary [URL]\n",
       "1    Very little pick-up by the dishonest media of ...\n",
       "2    Crooked Hillary Clinton likes to talk about th...\n",
       "3    Thank you Florida- a MOVEMENT that has never b...\n",
       "4    Join me Thursday in Florida &amp; Ohio!West Pa...\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10f279f60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f466cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_words=listofwords.value_counts()\n",
    "top_words_percent= top_words/len(listofwords)\n",
    "top_words.head(50).plot.bar()\n",
    "# top_words.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250988"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_chars=len(tweet_text_all)\n",
    "total_chars\n",
    "total_wordz=len((tweet_text_all.split()))\n",
    "total_wordz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique words 32293\n",
      "total number of unique chars 369\n"
     ]
    }
   ],
   "source": [
    "chars = set(tweet_text_all)\n",
    "words = set(tweet_text_all.split())\n",
    "print (\"total number of unique words\", len(words))\n",
    "print (\"total number of unique chars\", len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace apostrophes in dictionary keys \n",
    "for i in range (len(words)):\n",
    "    words[i]=words[i].replace(\"‘\", '').replace(\"’\", '').replace(\"'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=set(words)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create forward and reverse word index\n",
    "word_indices = dict((c, i) for i, c in enumerate(words, 1))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words,1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31907"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_indices)\n",
    "max(word_indices.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sentence list: 77465\n",
      "length of next_word list 77465\n"
     ]
    }
   ],
   "source": [
    "#choose step \n",
    "\n",
    "maxlen = 10\n",
    "step = 2\n",
    "\n",
    "sentences = []\n",
    "next_words = []\n",
    "next_words = []\n",
    "list_words = []\n",
    "\n",
    "sentences2 = []\n",
    "for i in range (len(tweet_text)):\n",
    "    list_words = tweet_text.iloc[i].split()\n",
    "    for i in range(len( list_words)):\n",
    "        list_words[i]=list_words[i].replace(\"‘\", '').replace(\"’\", '').replace(\"'\", '')\n",
    "    for i in range(0, len(list_words) - maxlen, step):\n",
    "        sentences2 = ' '.join(list_words[i: i + maxlen])\n",
    "        sentences.append(sentences2)\n",
    "        next_words.append((list_words[i + maxlen]))\n",
    "\n",
    "print ('length of sentence list:', len(sentences))\n",
    "print (\"length of next_word list\", len(next_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=[]\n",
    "y=[]\n",
    "for i, sentence in enumerate(sentences):\n",
    "    sequence=[]\n",
    "    for j, word in enumerate(sentence.split()):\n",
    "        sequence.append(word_indices[word])\n",
    "    sequences.append(sequence)\n",
    "    y.append(word_indices[next_words[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77465, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences=np.asarray(sequences)\n",
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5474, 11968,  3485, ...,  6441,  3387, 15857],\n",
       "       [ 3485, 26547, 15717, ..., 15857, 11838, 26547],\n",
       "       [15717, 29334, 26454, ..., 26547, 21416, 27948],\n",
       "       ...,\n",
       "       [ 6441,  1914,  7514, ..., 11705, 27439,  6462],\n",
       "       [ 7514, 22040, 20180, ...,  6462,  4936, 12173],\n",
       "       [20180, 15987, 13190, ..., 12173,  6441,  6324]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words= len(word_indices)+1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('../word_embeding/glove.twitter.27B.25d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31907"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(word_indices.values())\n",
    "len(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=25\n",
    "embedding_matrix = np.zeros((total_words, EMBEDDING_DIM)) \n",
    "for word, i in word_indices.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31908, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "for number in sequences:\n",
    "    X.append(embedding_matrix[number])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77465, 10, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31908, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31908, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)\n",
    "len(word_indices)\n",
    "len(sentences)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77465,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample=X_train[0:10000]\n",
    "y_train_sample=y_train[0:10000]\n",
    "X_test_sample=X_test[0:1000]\n",
    "y_test_sample=y_test[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20173,\n",
       " 11482,\n",
       " 31488,\n",
       " 31869,\n",
       " 10252,\n",
       " 29202,\n",
       " 8932,\n",
       " 8647,\n",
       " 12440,\n",
       " 26505,\n",
       " 17213,\n",
       " 17014,\n",
       " 29611,\n",
       " 21269,\n",
       " 5024,\n",
       " 9036,\n",
       " 7066,\n",
       " 13486,\n",
       " 17014,\n",
       " 27468,\n",
       " 22726,\n",
       " 26450,\n",
       " 13574,\n",
       " 15360,\n",
       " 14661,\n",
       " 5024,\n",
       " 17213,\n",
       " 19320,\n",
       " 4646,\n",
       " 2532,\n",
       " 5510,\n",
       " 10327,\n",
       " 9180,\n",
       " 258,\n",
       " 733,\n",
       " 17213,\n",
       " 15663,\n",
       " 7444,\n",
       " 17014,\n",
       " 14918,\n",
       " 8876,\n",
       " 12484,\n",
       " 12482,\n",
       " 12605,\n",
       " 11760,\n",
       " 17014,\n",
       " 30322,\n",
       " 8589,\n",
       " 10194,\n",
       " 5510,\n",
       " 14222,\n",
       " 11793,\n",
       " 24517,\n",
       " 8162,\n",
       " 20914,\n",
       " 18189,\n",
       " 14092,\n",
       " 17213,\n",
       " 24683,\n",
       " 1587,\n",
       " 27718,\n",
       " 28931,\n",
       " 17213,\n",
       " 3117,\n",
       " 14092,\n",
       " 1973,\n",
       " 4646,\n",
       " 1258,\n",
       " 17213,\n",
       " 4164,\n",
       " 3585,\n",
       " 15219,\n",
       " 12919,\n",
       " 10514,\n",
       " 27983,\n",
       " 14222,\n",
       " 18860,\n",
       " 20133,\n",
       " 4399,\n",
       " 9726,\n",
       " 3374,\n",
       " 21193,\n",
       " 9036,\n",
       " 5373,\n",
       " 18860,\n",
       " 4164,\n",
       " 24556,\n",
       " 10642,\n",
       " 31797,\n",
       " 17014]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train).shape\n",
    "y_train[10:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               78848     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 31908)             4116132   \n",
      "=================================================================\n",
      "Total params: 4,194,980\n",
      "Trainable params: 4,194,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.regularizers import L1L2\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "# embedding_layer= Embedding(total_words, EMBEDDING_DIM, weights=[embedding_matrix],input_length=max_seq,trainable=False)\n",
    "# sequence_input = Input(shape=(max_seq,), dtype='int32')\n",
    "# embedded_sequences= embedding_layer(sequence_input)\n",
    "model=Sequential()\n",
    "# e=Embedding(total_words, EMBEDDING_DIM, weights=[embedding_matrix],input_length=maxlen,trainable=False)\n",
    "# model.add(e)\n",
    "model.add(LSTM(128, input_shape=(maxlen, EMBEDDING_DIM), bias_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(512, return_sequences=False))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(total_words, activation=\"softmax\"))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "# sgd = optimizers.SGD(lr=0.01, clipvalue=0.5)\n",
    "model.compile(loss='sparse_categorical_crossentropy',  metrics=['accuracy'], optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "# model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "# model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model= load_model(\"../Saved_models/failed_on_99th_epoch_word_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 49577 samples, validate on 12395 samples\n",
      "Epoch 1/10\n",
      "26336/49577 [==============>...............] - ETA: 25s - loss: 8.0414 - acc: 0.0603"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e0f0e8bd0a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=3)\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.900000\n",
      "loss: 9.635607\n",
      "perplexity: 795.4386352619334\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_sample, y_test_sample, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print('loss: %f' % (loss))\n",
    "perplexity = np.exp2(loss)\n",
    "print ('perplexity: {}'.format(perplexity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i will be the U.S. and my great job. and the Dems They We including a big deal with Russia and people\n"
     ]
    }
   ],
   "source": [
    "print (generate_text(\"i will\", 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../failed_on_99th_epoch_word_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10639"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
