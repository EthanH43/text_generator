{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import optimizers\n",
    "import sys\n",
    "from keras.callbacks import LambdaCallback\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data=pd.read_csv('../Load_Tweets/data/tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = tweet_data['TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_all = tweet_data['TEXT'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAY TO PLAY POLITICS. #CrookedHillary [URL] Very little pick-up by the dishonest media of incredible information provided by WikiLeaks. So dishonest! Rigged system! Crooked Hillary Clinton likes to talk about the things she will do but she has been there for 30 years - why didn\\'t she do them? Thank you Florida- a MOVEMENT that has never been seen before and will never be seen again. Lets get out &amp;… [URL] Join me Thursday in Florida &amp; Ohio!West Palm Beach, FL at noon:[URL]Cincinnati, OH this 7:30pm:[URL] Wow, @CNN Town Hall questions were given to Crooked Hillary Clinton in advance of big debates against Bernie Sanders. Hillary &amp; CNN FRAUD! Thank you Texas! If you haven\\'t registered to VOTE- today is your last day. Go to: [URL] &amp; get ou… [URL] VOTER REGISTRATION DEADLINES TODAY. You can register now at: [URL] and get out to… [URL] DON\\'T LET HER FOOL US AGAIN. [URL] Crooked\\'s State Dept gave special attention to \"Friends of Bill\" after the Haiti Earthquake. Unbelievable! '"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text_all[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1513769 characters\n"
     ]
    }
   ],
   "source": [
    "print ('Length of text: {} characters'.format(len(tweet_text_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAY TO PLAY POLITICS. #CrookedHillary [URL] Very little pick-up by the dishonest media of incredible information provided by WikiLeaks. So dishonest! Rigged system! Crooked Hillary Clinton likes to talk about the things she will do but she has been t\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(tweet_text_all[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_words=pd.Series(tweet_text_all.split())\n",
    "# print ('Length of text: {} words'.format(len(list_of_words)))\n",
    "# word_vocab=set(list_of_words)\n",
    "# print ('{} unique words'.format(len(word_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tweet_text_all=re.sub('(\\w)\\.(\\w)', '\\\\1. \\\\2', tweet_text_all)\n",
    "tweet_text_all=re.sub('(\\w)(\\.{2,4})(\\w)', ' \\\\1 \\\\2 \\\\3', tweet_text_all)\n",
    "tweet_text_all=re.sub('(\\w)(\\.{2,4}) ', '\\\\1 \\\\2 ',tweet_text_all) #fdj... fdj ...\n",
    "tweet_text_all=re.sub(' (\\.{2,10})(\\w)', ' \\\\1 \\\\2',tweet_text_all) #...fdj ... fdj\n",
    "tweet_text_all=re.sub('[)(]', '', tweet_text_all) #can make paranteses their own token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_all=re.sub('!(.)',' ! \\\\1', tweet_text_all)\n",
    "tweet_text_all=re.sub('\\\"', '', tweet_text_all) # can keep the qoutes\n",
    "tweet_text_all=re.sub(\"\\'\", '', tweet_text_all)\n",
    "tweet_text_all=re.sub(\"\\”\", '', tweet_text_all)\n",
    "tweet_text_all=re.sub(\"\\‘\", '', tweet_text_all)\n",
    "tweet_text_all=re.sub(\"\\’\", '', tweet_text_all)\n",
    "tweet_text_all=re.sub(\"#(.)\", '# \\\\1', tweet_text_all) \n",
    "tweet_text_all=re.sub(\"@(.)\", '@ \\\\1', tweet_text_all)\n",
    "tweet_text_all=re.sub(\"(.),\", '\\\\1 ,', tweet_text_all)\n",
    "tweet_text_all=re.sub(\",(.)\", ', \\\\1', tweet_text_all)\n",
    "tweet_text_all=re.sub(\"(.):\", '\\\\1 :', tweet_text_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_words=pd.Series(tweet_text_all.split())\n",
    "# print ('Length of text: {} words'.format(len(list_of_words)))\n",
    "# word_vocab=set(list_of_words)\n",
    "# print ('{} unique words'.format(len(word_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAY TO PLAY POLITICS EOS # CrookedHillary [URL] Very little pick-up by the dishonest media of incredible information provided by WikiLeaks EOS So dishonest !  Rigged system !  Crooked Hillary Clinton likes to talk about the things she will do but she has been there for 30 years - why didnt she do them? Thank you Florida- a MOVEMENT that has never been seen before and will never be seen again EOS Lets get out &amp;… [URL] Join me Thursday in Florida &amp; Ohio ! West Palm Beach ,  FL at noon :[URL]Cincinnati ,  OH this 7 :30pm :[URL] Wow ,  @ CNN Town Hall questions were given to Crooked Hillary Clinton in advance of big debates against Bernie Sanders EOS Hillary &amp; CNN FRAUD !  Thank you Texas !  If you havent registered to VOTE- today is your last day EOS Go to : [URL] &amp; get ou… [URL] VOTER REGISTRATION DEADLINES TODAY EOS You can register now at : [URL] and get out to… [URL] DONT LET HER FOOL US AGAIN EOS [URL] Crookeds State Dept gave special attention to Friends of Bill afte'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text_all=re.sub('([^.])\\.([^.])', '\\\\1 EOS\\\\2', tweet_text_all) \n",
    "# tweet_text_all = tweet_text_all.replace(\".\", ' <EOS>')\n",
    "tweet_text_all[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 296283 words\n"
     ]
    }
   ],
   "source": [
    "list_of_words=pd.Series(tweet_text_all.split())\n",
    "print ('Length of text: {} words'.format(len(list_of_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20516 unique words\n"
     ]
    }
   ],
   "source": [
    "#number of unique words\n",
    "word_vocab=sorted(set(list_of_words))\n",
    "print ('{} unique words'.format(len(word_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(tweet_text_all))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #replace apostrophes in dictionary keys \n",
    "# for i in range (len(list_of_words)):\n",
    "#     list_of_words[i]=list_of_words[i].replace(\"‘\", '').replace(\"’\", '').replace(\"'\", '').replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #see how many words after apostrophe deletion\n",
    "# word_vocab=sorted(set(list_of_words))\n",
    "# print ('{} unique words'.format(len(word_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab.append('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNK'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vocab[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create forward and reverse word index\n",
    "word2idx = dict((c, i) for i, c in enumerate(word_vocab, 1))\n",
    "# idx2word = dict((i, c) for i, c in enumerate(word_vocab,1 ))\n",
    "idx2word= np.asarray(word_vocab)\n",
    "\n",
    "text_as_int = np.array([word2idx[w] for w in list_of_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '!' :   1,\n",
      "  '!#':   2,\n",
      "  '!Full':   3,\n",
      "  '#' :   4,\n",
      "  '$' :   5,\n",
      "  '$$':   6,\n",
      "  '$$$':   7,\n",
      "  '$1':   8,\n",
      "  '$10':   9,\n",
      "  '$100':  10,\n",
      "  '$100s':  11,\n",
      "  '$10T':  12,\n",
      "  '$11':  13,\n",
      "  '$12':  14,\n",
      "  '$120':  15,\n",
      "  '$120…':  16,\n",
      "  '$12M':  17,\n",
      "  '$13':  18,\n",
      "  '$13M':  19,\n",
      "  '$145':  20,\n",
      "  '$15':  21,\n",
      "  '$150':  22,\n",
      "  '$150M?':  23,\n",
      "  '$151':  24,\n",
      "  '$16':  25,\n",
      "  '$17':  26,\n",
      "  '$18':  27,\n",
      "  '$180':  28,\n",
      "  '$19':  29,\n",
      "  '$1BILLION':  30,\n",
      "  '$1M':  31,\n",
      "  '$2':  32,\n",
      "  '$20':  33,\n",
      "  '$200':  34,\n",
      "  '$20T':  35,\n",
      "  '$21':  36,\n",
      "  '$22':  37,\n",
      "  '$225':  38,\n",
      "  '$23':  39,\n",
      "  '$25':  40,\n",
      "  '$26':  41,\n",
      "  '$264':  42,\n",
      "  '$28':  43,\n",
      "  '$3':  44,\n",
      "  '$3+':  45,\n",
      "  '$30':  46,\n",
      "  '$300':  47,\n",
      "  '$33':  48,\n",
      "  '$35M':  49,\n",
      "  '$4':  50,\n",
      "  '$40':  51,\n",
      "  '$400':  52,\n",
      "  '$400K':  53,\n",
      "  '$43M':  54,\n",
      "  '$5':  55,\n",
      "  '$50':  56,\n",
      "  '$500':  57,\n",
      "  '$500k':  58,\n",
      "  '$517':  59,\n",
      "  '$52':  60,\n",
      "  '$54':  61,\n",
      "  '$55':  62,\n",
      "  '$56':  63,\n",
      "  '$6':  64,\n",
      "  '$603':  65,\n",
      "  '$67':  66,\n",
      "  '$6M':  67,\n",
      "  '$7':  68,\n",
      "  '$700':  69,\n",
      "  '$71':  70,\n",
      "  '$716':  71,\n",
      "  '$729M':  72,\n",
      "  '$80':  73,\n",
      "  '$800':  74,\n",
      "  '$80k':  75,\n",
      "  '$817':  76,\n",
      "  '$82':  77,\n",
      "  '$89':  78,\n",
      "  '$9':  79,\n",
      "  '$972':  80,\n",
      "  '$9trillion':  81,\n",
      "  '$Billions':  82,\n",
      "  '$billions':  83,\n",
      "  '$s':  84,\n",
      "  '&amp;':  85,\n",
      "  '&amp;TRUMPS':  86,\n",
      "  '&amp;pocketbook':  87,\n",
      "  '&amp;…':  88,\n",
      "  '&gt;[URL]':  89,\n",
      "  '&lt;MOST':  90,\n",
      "  '**REPORT':  91,\n",
      "  '*NOT*':  92,\n",
      "  '+' :  93,\n",
      "  '+1':  94,\n",
      "  '+15':  95,\n",
      "  '+2':  96,\n",
      "  '+235':  97,\n",
      "  '+37':  98,\n",
      "  ',' :  99,\n",
      "  '-' : 100,\n",
      "  '-&gt;': 101,\n",
      "  '--': 102,\n",
      "  '--&gt;': 103,\n",
      "  '---': 104,\n",
      "  '--TRUMPS': 105,\n",
      "  '--despite': 106,\n",
      "  '--everybody': 107,\n",
      "  '-1': 108,\n",
      "  '-2/11': 109,\n",
      "  '-@': 110,\n",
      "  '-Chris': 111,\n",
      "  '-Kyle': 112,\n",
      "  '-President': 113,\n",
      "  '-Senator': 114,\n",
      "  '-Stuart': 115,\n",
      "  '-WSJ[URL]': 116,\n",
      "  '-Wishing': 117,\n",
      "  '-and': 118,\n",
      "  '-…': 119,\n",
      "  '..': 120,\n",
      "  '...': 121,\n",
      "  '....': 122,\n",
      "  '.....': 123,\n",
      "  '......': 124,\n",
      "  '......#': 125,\n",
      "  '.......': 126,\n",
      "  '........': 127,\n",
      "  '.....Carter': 128,\n",
      "  '.....It': 129,\n",
      "  '....@': 130,\n",
      "  '....the': 131,\n",
      "  '....we': 132,\n",
      "  '....“$17': 133,\n",
      "  '...collusion': 134,\n",
      "  '..enthusiastic': 135,\n",
      "  '.@': 136,\n",
      "  '/' : 137,\n",
      "  '/@': 138,\n",
      "  '0' : 139,\n",
      "  '0%': 140,\n",
      "  '00': 141,\n",
      "  '000': 142,\n",
      "  '000+': 143,\n",
      "  '000?': 144,\n",
      "  '000…': 145,\n",
      "  '000📈': 146,\n",
      "  '000📈21': 147,\n",
      "  '000📈22': 148,\n",
      "  '000📈this': 149,\n",
      "  '007cigarjoe': 150,\n",
      "  '03-': 151,\n",
      "  '036': 152,\n",
      "  '075': 153,\n",
      "  '0Source': 154,\n",
      "  '1' : 155,\n",
      "  '1%': 156,\n",
      "  '1-23-16': 157,\n",
      "  '1-800-342-3557[URL]Volunteer': 158,\n",
      "  '1-800-FL-HELP-1[URL]': 159,\n",
      "  '1-in-5': 160,\n",
      "  '1/1024': 161,\n",
      "  '1/10th': 162,\n",
      "  '1/19/2017': 163,\n",
      "  '1/2': 164,\n",
      "  '1/2%': 165,\n",
      "  '1/20': 166,\n",
      "  '10': 167,\n",
      "  '10%': 168,\n",
      "  '10%Kasich': 169,\n",
      "  '10/18': 170,\n",
      "  '10/3': 171,\n",
      "  '100': 172,\n",
      "  '100#': 173,\n",
      "  '100%': 174,\n",
      "  '1000': 175,\n",
      "  '1001': 176,\n",
      "  '100TH': 177,\n",
      "  '100k': 178,\n",
      "  '100th': 179,\n",
      "  '100yrs': 180,\n",
      "  '100…': 181,\n",
      "  '101': 182,\n",
      "  '102nd': 183,\n",
      "  '105': 184,\n",
      "  '106-year-old': 185,\n",
      "  '109': 186,\n",
      "  '10am': 187,\n",
      "  '10am-': 188,\n",
      "  '10k': 189,\n",
      "  '10p': 190,\n",
      "  '10pE': 191,\n",
      "  '10pm': 192,\n",
      "  '10pmE': 193,\n",
      "  '10th': 194,\n",
      "  '11': 195,\n",
      "  '11%': 196,\n",
      "  '11+': 197,\n",
      "  '11/7/2016Scranton': 198,\n",
      "  '11/8': 199,\n",
      "  '11/8/16': 200,\n",
      "  '11/8/16-': 201,\n",
      "  '11/8/2016': 202,\n",
      "  '11/8/2016-': 203,\n",
      "  '11/8/2016}': 204,\n",
      "  '110': 205,\n",
      "  '1115': 206,\n",
      "  '112%': 207,\n",
      "  '113': 208,\n",
      "  '114th': 209,\n",
      "  '115': 210,\n",
      "  '116%': 211,\n",
      "  '119': 212,\n",
      "  '11a': 213,\n",
      "  '11am': 214,\n",
      "  '11am6/11': 215,\n",
      "  '11phenomenon': 216,\n",
      "  '11pm': 217,\n",
      "  '11pmE': 218,\n",
      "  '11th': 219,\n",
      "  '12': 220,\n",
      "  '12%': 221,\n",
      "  '12%Carson': 222,\n",
      "  '12%Rubio': 223,\n",
      "  '12-Yr': 224,\n",
      "  '12/1': 225,\n",
      "  '12/1/16': 226,\n",
      "  '12/21': 227,\n",
      "  '12/6-': 228,\n",
      "  '12/7/1941': 229,\n",
      "  '122': 230,\n",
      "  '122%': 231,\n",
      "  '1237': 232,\n",
      "  '125': 233,\n",
      "  '126': 234,\n",
      "  '127': 235,\n",
      "  '129': 236,\n",
      "  '12K': 237,\n",
      "  '12pm': 238,\n",
      "  '12th': 239,\n",
      "  '13': 240,\n",
      "  '13%': 241,\n",
      "  '13%Bush': 242,\n",
      "  '131': 243,\n",
      "  '1314': 244,\n",
      "  '134': 245,\n",
      "  '138': 246,\n",
      "  '1380': 247,\n",
      "  '139': 248,\n",
      "  '13K': 249,\n",
      "  '13th': 250,\n",
      "  '14': 251,\n",
      "  '14%Kasich': 252,\n",
      "  '14-Year': 253,\n",
      "  '142': 254,\n",
      "  '142018': 255,\n",
      "  '143': 256,\n",
      "  '145': 257,\n",
      "  '147': 258,\n",
      "  '149': 259,\n",
      "  '14th': 260,\n",
      "  '15': 261,\n",
      "  '15%': 262,\n",
      "  '15%Rubio': 263,\n",
      "  '15%[URL]': 264,\n",
      "  '15-0': 265,\n",
      "  '150': 266,\n",
      "  '152': 267,\n",
      "  '152nd': 268,\n",
      "  '155': 269,\n",
      "  '158': 270,\n",
      "  '16': 271,\n",
      "  '16%': 272,\n",
      "  '16-Year': 273,\n",
      "  '16-year': 274,\n",
      "  '166': 275,\n",
      "  '168': 276,\n",
      "  '16th': 277,\n",
      "  '17': 278,\n",
      "  '17%': 279,\n",
      "  '17%Cruz': 280,\n",
      "  '17-Point': 281,\n",
      "  '17-year': 282,\n",
      "  '170': 283,\n",
      "  '1714': 284,\n",
      "  '174': 285,\n",
      "  '179': 286,\n",
      "  '17B': 287,\n",
      "  '17th': 288,\n",
      "  '18': 289,\n",
      "  '18%': 290,\n",
      "  '18%Carson': 291,\n",
      "  '18%Rubio': 292,\n",
      "  '180': 293,\n",
      "  '185': 294,\n",
      "  '18th': 295,\n",
      "  '18years': 296,\n",
      "  '19': 297,\n",
      "  '19%': 298,\n",
      "  '1903': 299,\n",
      "  '1908': 300,\n",
      "  '1918': 301,\n",
      "  '1929': 302,\n",
      "  '1941': 303,\n",
      "  '1944': 304,\n",
      "  '1949z': 305,\n",
      "  '1957': 306,\n",
      "  '1960': 307,\n",
      "  '1969': 308,\n",
      "  '197': 309,\n",
      "  '1970': 310,\n",
      "  '1970Under': 311,\n",
      "  '1970s': 312,\n",
      "  '1973': 313,\n",
      "  '1976': 314,\n",
      "  '1980[URL]': 315,\n",
      "  '1983': 316,\n",
      "  '1988': 317,\n",
      "  '1990': 318,\n",
      "  '1993': 319,\n",
      "  '1994': 320,\n",
      "  '1997': 321,\n",
      "  '1999': 322,\n",
      "  '19pts': 323,\n",
      "  '1K': 324,\n",
      "  '1lion': 325,\n",
      "  '1million': 326,\n",
      "  '1pmE': 327,\n",
      "  '1pm…': 328,\n",
      "  '1sonny12': 329,\n",
      "  '1st': 330,\n",
      "  '1…': 331,\n",
      "  '2' : 332,\n",
      "  '2%': 333,\n",
      "  '2%…': 334,\n",
      "  '2+': 335,\n",
      "  '2-point': 336,\n",
      "  '2/1/16': 337,\n",
      "  '2/1/2016': 338,\n",
      "  '2/2': 339,\n",
      "  '2/24/2016': 340,\n",
      "  '2/2[URL]': 341,\n",
      "  '2/3': 342,\n",
      "  '2/8': 343,\n",
      "  '20': 344,\n",
      "  '20%': 345,\n",
      "  '20%Join': 346,\n",
      "  '200': 347,\n",
      "  '200%': 348,\n",
      "  '200+': 349,\n",
      "  '2000': 350,\n",
      "  '2000...': 351,\n",
      "  '2001#': 352,\n",
      "  '2002': 353,\n",
      "  '2004': 354,\n",
      "  '2004📈[URL]': 355,\n",
      "  '2005': 356,\n",
      "  '2006': 357,\n",
      "  '2008': 358,\n",
      "  '2008-2011': 359,\n",
      "  '2009': 360,\n",
      "  '200Total': 361,\n",
      "  '200k': 362,\n",
      "  '2010': 363,\n",
      "  '2011': 364,\n",
      "  '2012': 365,\n",
      "  '2013': 366,\n",
      "  '2014': 367,\n",
      "  '2014-2016': 368,\n",
      "  '2015': 369,\n",
      "  '2016': 370,\n",
      "  '2016/2017': 371,\n",
      "  '2017': 372,\n",
      "  '2017Jambo-': 373,\n",
      "  '2018': 374,\n",
      "  '2019': 375,\n",
      "  '2020': 376,\n",
      "  '2020?': 377,\n",
      "  '2020TAKEBACKTHEHOUSE': 378,\n",
      "  '2024': 379,\n",
      "  '2025': 380,\n",
      "  '2026': 381,\n",
      "  '2032': 382,\n",
      "  '205': 383,\n",
      "  '209': 384,\n",
      "  '20K': 385,\n",
      "  '20th': 386,\n",
      "  '21': 387,\n",
      "  '2142': 388,\n",
      "  '217-185': 389,\n",
      "  '219': 390,\n",
      "  '21st': 391,\n",
      "  '22': 392,\n",
      "  '22-': 393,\n",
      "  '222016': 394,\n",
      "  '223': 395,\n",
      "  '226th': 396,\n",
      "  '227-205': 397,\n",
      "  '228': 398,\n",
      "  '22nd': 399,\n",
      "  '23': 400,\n",
      "  '23%': 401,\n",
      "  '230': 402,\n",
      "  '232': 403,\n",
      "  '233%': 404,\n",
      "  '236th': 405,\n",
      "  '23M': 406,\n",
      "  '23rd': 407,\n",
      "  '24': 408,\n",
      "  '24%': 409,\n",
      "  '24/7': 410,\n",
      "  '24/7/365': 411,\n",
      "  '240': 412,\n",
      "  '240%': 413,\n",
      "  '241': 414,\n",
      "  '241st': 415,\n",
      "  '242': 416,\n",
      "  '242NavyBday': 417,\n",
      "  '242nd': 418,\n",
      "  '243NavyBday': 419,\n",
      "  '243rd': 420,\n",
      "  '245': 421,\n",
      "  '247': 422,\n",
      "  '249': 423,\n",
      "  '24th': 424,\n",
      "  '25': 425,\n",
      "  '25%': 426,\n",
      "  '250': 427,\n",
      "  '25K': 428,\n",
      "  '25M': 429,\n",
      "  '25mil': 430,\n",
      "  '25th': 431,\n",
      "  '25th-': 432,\n",
      "  '26': 433,\n",
      "  '26%': 434,\n",
      "  '266': 435,\n",
      "  '267': 436,\n",
      "  '27': 437,\n",
      "  '27%': 438,\n",
      "  '270': 439,\n",
      "  '270%': 440,\n",
      "  '275%': 441,\n",
      "  '27th': 442,\n",
      "  '28': 443,\n",
      "  '28%Cruz': 444,\n",
      "  '29': 445,\n",
      "  '29%': 446,\n",
      "  '290CLINTON': 447,\n",
      "  '292': 448,\n",
      "  '295': 449,\n",
      "  '2A': 450,\n",
      "  '2A#': 451,\n",
      "  '2M': 452,\n",
      "  '2ND': 453,\n",
      "  '2nd': 454,\n",
      "  '2n…': 455,\n",
      "  '2p/10p': 456,\n",
      "  '2pm-': 457,\n",
      "  '2pm[URL]Colorado': 458,\n",
      "  '2pm[URL]MICHIGAN': 459,\n",
      "  '2yrs-an': 460,\n",
      "  '3' : 461,\n",
      "  '3%': 462,\n",
      "  '3%Christie': 463,\n",
      "  '3+': 464,\n",
      "  '3-1': 465,\n",
      "  '3-5': 466,\n",
      "  '3-D': 467,\n",
      "  '3/15': 468,\n",
      "  '3/4': 469,\n",
      "  '3/5/2016': 470,\n",
      "  '3/8/2016': 471,\n",
      "  '30': 472,\n",
      "  '30%': 473,\n",
      "  '30+': 474,\n",
      "  '300': 475,\n",
      "  '300%': 476,\n",
      "  '3000': 477,\n",
      "  '300th': 478,\n",
      "  '304': 479,\n",
      "  '304-227': 480,\n",
      "  '306': 481,\n",
      "  '306-223?': 482,\n",
      "  '30s': 483,\n",
      "  '31': 484,\n",
      "  '312': 485,\n",
      "  '31st': 486,\n",
      "  '32': 487,\n",
      "  '320': 488,\n",
      "  '325': 489,\n",
      "  '33': 490,\n",
      "  '33%': 491,\n",
      "  '331': 492,\n",
      "  '341': 493,\n",
      "  '342': 494,\n",
      "  '35': 495,\n",
      "  '35%': 496,\n",
      "  '35%Kasich': 497,\n",
      "  '350': 498,\n",
      "  '36': 499,\n",
      "  '36%': 500,\n",
      "  '36%Cruz': 501,\n",
      "  '360': 502,\n",
      "  '362017': 503,\n",
      "  '365': 504,\n",
      "  '36th': 505,\n",
      "  '37': 506,\n",
      "  '37%': 507,\n",
      "  '375': 508,\n",
      "  '38': 509,\n",
      "  '38%': 510,\n",
      "  '382nd': 511,\n",
      "  '38K': 512,\n",
      "  '38th📈Record': 513,\n",
      "  '39': 514,\n",
      "  '39%': 515,\n",
      "  '39%#': 516,\n",
      "  '390': 517,\n",
      "  '392': 518,\n",
      "  '3?': 519,\n",
      "  '3B-$1': 520,\n",
      "  '3M': 521,\n",
      "  '3pm': 522,\n",
      "  '3pm-': 523,\n",
      "  '3pm6/13': 524,\n",
      "  '3pm[URL]': 525,\n",
      "  '3pm…': 526,\n",
      "  '3rd': 527,\n",
      "  '3…': 528,\n",
      "  '4' : 529,\n",
      "  '4%': 530,\n",
      "  '4%Jeb': 531,\n",
      "  '4--': 532,\n",
      "  '4-8': 533,\n",
      "  '4/9': 534,\n",
      "  '4/9/18': 535,\n",
      "  '40': 536,\n",
      "  '40%': 537,\n",
      "  '400': 538,\n",
      "  '4000': 539,\n",
      "  '401-ks': 540,\n",
      "  '401k': 541,\n",
      "  '401ks': 542,\n",
      "  '401k…': 543,\n",
      "  '403': 544,\n",
      "  '40YearsofFailure': 545,\n",
      "  '40th': 546,\n",
      "  '41%': 547,\n",
      "  '41[URL]': 548,\n",
      "  '42': 549,\n",
      "  '42%': 550,\n",
      "  '426': 551,\n",
      "  '43': 552,\n",
      "  '43%': 553,\n",
      "  '43%Clinton': 554,\n",
      "  '43%Hillary': 555,\n",
      "  '43-39': 556,\n",
      "  '44': 557,\n",
      "  '44%': 558,\n",
      "  '442': 559,\n",
      "  '44th📈Record': 560,\n",
      "  '45': 561,\n",
      "  '45%': 562,\n",
      "  '45-year': 563,\n",
      "  '450': 564,\n",
      "  '45th': 565,\n",
      "  '46': 566,\n",
      "  '46%': 567,\n",
      "  '46-44': 568,\n",
      "  '465': 569,\n",
      "  '47': 570,\n",
      "  '47%': 571,\n",
      "  '47%...and': 572,\n",
      "  '47-43': 573,\n",
      "  '47?': 574,\n",
      "  '48': 575,\n",
      "  '48%': 576,\n",
      "  '481': 577,\n",
      "  '49': 578,\n",
      "  '49%': 579,\n",
      "  '49-year': 580,\n",
      "  '495': 581,\n",
      "  '4K': 582,\n",
      "  '4months': 583,\n",
      "  '4our': 584,\n",
      "  '4p': 585,\n",
      "  '4pm': 586,\n",
      "  '4pmE': 587,\n",
      "  '4th': 588,\n",
      "  '4yrs': 589,\n",
      "  '5' : 590,\n",
      "  '5%': 591,\n",
      "  '5%Carson': 592,\n",
      "  '5-0': 593,\n",
      "  '5-1-1': 594,\n",
      "  '5-10': 595,\n",
      "  '5-7pm': 596,\n",
      "  '5/14/2017': 597,\n",
      "  '5/20/2017': 598,\n",
      "  '5/25/16': 599,\n",
      "  '5/31/99': 600,\n",
      "  '50': 601,\n",
      "  '50%': 602,\n",
      "  '50%[URL]': 603,\n",
      "  '500': 604,\n",
      "  '500%': 605,\n",
      "  '500+': 606,\n",
      "  '5000': 607,\n",
      "  '500Days': 608,\n",
      "  '500th': 609,\n",
      "  '50K': 610,\n",
      "  '50s': 611,\n",
      "  '50th': 612,\n",
      "  '51': 613,\n",
      "  '51%': 614,\n",
      "  '51yrs': 615,\n",
      "  '52': 616,\n",
      "  '52%': 617,\n",
      "  '53': 618,\n",
      "  '53%': 619,\n",
      "  '533': 620,\n",
      "  '539': 621,\n",
      "  '53rd': 622,\n",
      "  '546': 623,\n",
      "  '548': 624,\n",
      "  '55': 625,\n",
      "  '55%...': 626,\n",
      "  '550%': 627,\n",
      "  '551': 628,\n",
      "  '55Lidsville': 629,\n",
      "  '562': 630,\n",
      "  '57': 631,\n",
      "  '577': 632,\n",
      "  '58': 633,\n",
      "  '589': 634,\n",
      "  '5895': 635,\n",
      "  '59%': 636,\n",
      "  '5G': 637,\n",
      "  '5K+': 638,\n",
      "  '5X': 639,\n",
      "  '5pm': 640,\n",
      "  '5th': 641,\n",
      "  '6' : 642,\n",
      "  '6%': 643,\n",
      "  '6%Rubio': 644,\n",
      "  '6%Simon': 645,\n",
      "  '6/10': 646,\n",
      "  '60': 647,\n",
      "  '60%': 648,\n",
      "  '600': 649,\n",
      "  '600-700': 650,\n",
      "  '6000': 651,\n",
      "  '60Minutes': 652,\n",
      "  '61%Clinton': 653,\n",
      "  '610-': 654,\n",
      "  '62': 655,\n",
      "  '62%': 656,\n",
      "  '620': 657,\n",
      "  '623': 658,\n",
      "  '63': 659,\n",
      "  '64': 660,\n",
      "  '64%': 661,\n",
      "  '646': 662,\n",
      "  '65%': 663,\n",
      "  '66%': 664,\n",
      "  '67': 665,\n",
      "  '675': 666,\n",
      "  '68': 667,\n",
      "  '685': 668,\n",
      "  '69': 669,\n",
      "  '69%': 670,\n",
      "  '69-30': 671,\n",
      "  '692-a': 672,\n",
      "  '6B': 673,\n",
      "  '6Days': 674,\n",
      "  '6G': 675,\n",
      "  '6pm': 676,\n",
      "  '6pm[URL]': 677,\n",
      "  '6pm[URL]Colorado': 678,\n",
      "  '6pm[URL]VIRGINIA': 679,\n",
      "  '6th': 680,\n",
      "  '7' : 681,\n",
      "  '7%': 682,\n",
      "  '7%Cruz': 683,\n",
      "  '7%Via': 684,\n",
      "  '70': 685,\n",
      "  '70%': 686,\n",
      "  '700': 687,\n",
      "  '702': 688,\n",
      "  '70th': 689,\n",
      "  '716': 690,\n",
      "  '71st': 691,\n",
      "  '72': 692,\n",
      "  '72%': 693,\n",
      "  '720a': 694,\n",
      "  '7213': 695,\n",
      "  '724': 696,\n",
      "  '73': 697,\n",
      "  '737': 698,\n",
      "  '737;': 699,\n",
      "  '739': 700,\n",
      "  '73rd': 701,\n",
      "  '74': 702,\n",
      "  '747': 703,\n",
      "  '749': 704,\n",
      "  '74th': 705,\n",
      "  '75': 706,\n",
      "  '75%': 707,\n",
      "  '75th': 708,\n",
      "  '76%': 709,\n",
      "  '762': 710,\n",
      "  '77': 711,\n",
      "  '77%': 712,\n",
      "  '772': 713,\n",
      "  '77wabcradio': 714,\n",
      "  '78%': 715,\n",
      "  '79%': 716,\n",
      "  '7A': 717,\n",
      "  '7K': 718,\n",
      "  '7PM': 719,\n",
      "  '7am': 720,\n",
      "  '7am/et': 721,\n",
      "  '7p': 722,\n",
      "  '7pm': 723,\n",
      "  '7pm-': 724,\n",
      "  '7pmE': 725,\n",
      "  '7th': 726,\n",
      "  '7yr': 727,\n",
      "  '7yrs': 728,\n",
      "  '8' : 729,\n",
      "  '8%': 730,\n",
      "  '8%Carson': 731,\n",
      "  '80': 732,\n",
      "  '80%': 733,\n",
      "  '80%Clinton': 734,\n",
      "  '80-100': 735,\n",
      "  '800': 736,\n",
      "  '800-': 737,\n",
      "  '8000': 738,\n",
      "  '804StreetMedia': 739,\n",
      "  '81': 740,\n",
      "  '823': 741,\n",
      "  '826': 742,\n",
      "  '83%': 743,\n",
      "  '84': 744,\n",
      "  '85': 745,\n",
      "  '858': 746,\n",
      "  '863': 747,\n",
      "  '87': 748,\n",
      "  '87%': 749,\n",
      "  '87-12': 750,\n",
      "  '874': 751,\n",
      "  '8am': 752,\n",
      "  '8amE': 753,\n",
      "  '8pm': 754,\n",
      "  '8pm6/11': 755,\n",
      "  '8pmE': 756,\n",
      "  '8t': 757,\n",
      "  '8th': 758,\n",
      "  '8th…': 759,\n",
      "  '9' : 760,\n",
      "  '9%': 761,\n",
      "  '9-0': 762,\n",
      "  '9-O': 763,\n",
      "  '9/11': 764,\n",
      "  '9/21/12': 765,\n",
      "  '9/29/17': 766,\n",
      "  '9/9/16': 767,\n",
      "  '90': 768,\n",
      "  '90%': 769,\n",
      "  '900': 770,\n",
      "  '900+': 771,\n",
      "  '91%': 772,\n",
      "  '911': 773,\n",
      "  '92': 774,\n",
      "  '92%': 775,\n",
      "  '93': 776,\n",
      "  '93%': 777,\n",
      "  '93%?': 778,\n",
      "  '93-5': 779,\n",
      "  '93101Dianne': 780,\n",
      "  '95': 781,\n",
      "  '95%': 782,\n",
      "  '9500': 783,\n",
      "  '959': 784,\n",
      "  '96%': 785,\n",
      "  '965': 786,\n",
      "  '97%': 787,\n",
      "  '98%': 788,\n",
      "  '980;': 789,\n",
      "  '99': 790,\n",
      "  '99%': 791,\n",
      "  '99th': 792,\n",
      "  '9am': 793,\n",
      "  '9p': 794,\n",
      "  '9pm': 795,\n",
      "  '9pmE': 796,\n",
      "  '9pmET': 797,\n",
      "  '9th': 798,\n",
      "  ':' : 799,\n",
      "  ':-': 800,\n",
      "  ':-Bad': 801,\n",
      "  ':-Meets': 802,\n",
      "  ':-Unemployment': 803,\n",
      "  ':-Wage': 804,\n",
      "  ':00': 805,\n",
      "  ':00am': 806,\n",
      "  ':00amE': 807,\n",
      "  ':00pm': 808,\n",
      "  ':00pmE': 809,\n",
      "  ':02': 810,\n",
      "  ':08amE;': 811,\n",
      "  ':1': 812,\n",
      "  ':10pm': 813,\n",
      "  ':15': 814,\n",
      "  ':18': 815,\n",
      "  ':2015': 816,\n",
      "  ':22': 817,\n",
      "  ':30': 818,\n",
      "  ':30am': 819,\n",
      "  ':30pm': 820,\n",
      "  ':30pm#': 821,\n",
      "  ':30pm-': 822,\n",
      "  ':30pmE': 823,\n",
      "  ':30pm[URL]': 824,\n",
      "  ':30p…': 825,\n",
      "  ':35': 826,\n",
      "  ':35pmE': 827,\n",
      "  ':40': 828,\n",
      "  ':45': 829,\n",
      "  ':45pm': 830,\n",
      "  ':45pmE': 831,\n",
      "  ':@': 832,\n",
      "  ':A': 833,\n",
      "  ':At': 834,\n",
      "  ':Daytona': 835,\n",
      "  ':Do': 836,\n",
      "  ':DonaldTrump': 837,\n",
      "  ':Golden': 838,\n",
      "  ':I': 839,\n",
      "  ':In': 840,\n",
      "  ':Kudos': 841,\n",
      "  ':Manchester': 842,\n",
      "  ':Pocahontas': 843,\n",
      "  ':President': 844,\n",
      "  ':Prior': 845,\n",
      "  ':Springfield': 846,\n",
      "  ':TRUMP': 847,\n",
      "  ':The': 848,\n",
      "  ':Trump': 849,\n",
      "  ':Watch': 850,\n",
      "  ':[URL]': 851,\n",
      "  ':[URL]Cincinnati': 852,\n",
      "  ':[URL]Eugene': 853,\n",
      "  ':[URL]Geneva-7pm…': 854,\n",
      "  ':[URL]Idaho': 855,\n",
      "  ':[URL]Las': 856,\n",
      "  ':[URL]Lynden': 857,\n",
      "  ':[URL]Michigan': 858,\n",
      "  ':[URL]Mississippi': 859,\n",
      "  ':[URL]SATURDAY': 860,\n",
      "  ':[URL]Tallahassee': 861,\n",
      "  ':[URL]Toledo-4pm': 862,\n",
      "  ':[URL]WEDNESDAY': 863,\n",
      "  ':[URL]Warren': 864,\n",
      "  ':“REMEMBER': 865,\n",
      "  ':“The': 866,\n",
      "  ':…': 867,\n",
      "  ':☑️#': 868,\n",
      "  ':☑️Keep': 869,\n",
      "  ':✅Eliminate': 870,\n",
      "  ':✅Wont': 871,\n",
      "  ':✔lowers': 872,\n",
      "  ':➡️KS➡️NC➡️TNGet': 873,\n",
      "  '=' : 874,\n",
      "  '?' : 875,\n",
      "  '???': 876,\n",
      "  '?Are': 877,\n",
      "  '@' : 878,\n",
      "  'A' : 879,\n",
      "  'A+': 880,\n",
      "  'A-': 881,\n",
      "  'A..': 882,\n",
      "  'AAA': 883,\n",
      "  'ABANDONED': 884,\n",
      "  'ABC': 885,\n",
      "  'ABC/Washington': 886,\n",
      "  'ABC2020': 887,\n",
      "  'ABC?': 888,\n",
      "  'ABCNewsRadio': 889,\n",
      "  'ABCPolitics': 890,\n",
      "  'ABCWorldNews': 891,\n",
      "  'ABOUT': 892,\n",
      "  'ABSOLUTE': 893,\n",
      "  'ABSURD': 894,\n",
      "  'AC': 895,\n",
      "  'AC360': 896,\n",
      "  'ACCEPTABLE': 897,\n",
      "  'ACCEPTANCE': 898,\n",
      "  'ACROSS': 899,\n",
      "  'ACT': 900,\n",
      "  'ACTION': 901,\n",
      "  'ACU': 902,\n",
      "  'ADDITIONAL': 903,\n",
      "  'ADDRESS': 904,\n",
      "  'ADDRESS🇺🇸': 905,\n",
      "  'ADMINISTRATION': 906,\n",
      "  'ADMIRALS': 907,\n",
      "  'ADP': 908,\n",
      "  'AFBF100': 909,\n",
      "  'AFBF18': 910,\n",
      "  'AFBF18On': 911,\n",
      "  'AFGHAN': 912,\n",
      "  'AFL-CIO': 913,\n",
      "  'AFLCIO': 914,\n",
      "  'AFRAID': 915,\n",
      "  'AFTER': 916,\n",
      "  'AFTERNOON': 917,\n",
      "  'AG': 918,\n",
      "  'AGAIN': 919,\n",
      "  'AGAINST': 920,\n",
      "  'AGAIN…': 921,\n",
      "  'AGAIN🇺🇸': 922,\n",
      "  'AGENDA': 923,\n",
      "  'AGENT': 924,\n",
      "  'AGPamBondi': 925,\n",
      "  'AGREE': 926,\n",
      "  'AGREED': 927,\n",
      "  'AG…': 928,\n",
      "  'AHCA': 929,\n",
      "  'AHEAD': 930,\n",
      "  'AIPAC2016': 931,\n",
      "  'AIR': 932,\n",
      "  'AK': 933,\n",
      "  'AK_TWEET': 934,\n",
      "  'AL': 935,\n",
      "  'ALABAMA': 936,\n",
      "  'ALAN': 937,\n",
      "  'ALConv2017': 938,\n",
      "  'ALConvention2016': 939,\n",
      "  'ALERT': 940,\n",
      "  'ALIENS': 941,\n",
      "  'ALL': 942,\n",
      "  'ALL-TIME': 943,\n",
      "  'ALLEGATIONS': 944,\n",
      "  'ALLOWED': 945,\n",
      "  'ALREADY': 946,\n",
      "  'ALSO': 947,\n",
      "  'ALWAYS': 948,\n",
      "  'AM': 949,\n",
      "  'AMAZING': 950,\n",
      "  'AMENDMENT': 951,\n",
      "  'AMERIC': 952,\n",
      "  'AMERICA': 953,\n",
      "  'AMERICAN': 954,\n",
      "  'AMERICANS': 955,\n",
      "  'AMERICANS-#': 956,\n",
      "  'AMERICANS🇺🇸[URL]': 957,\n",
      "  'AMERICAS': 958,\n",
      "  'AMERICA…': 959,\n",
      "  'AMERICA🇺🇸[URL][URL][URL]': 960,\n",
      "  'AMVETS': 961,\n",
      "  'AM…': 962,\n",
      "  'AN': 963,\n",
      "  'ANARCHY': 964,\n",
      "  'ANCHORS': 965,\n",
      "  'AND': 966,\n",
      "  'ANDREW': 967,\n",
      "  'ANGER': 968,\n",
      "  'ANGRY': 969,\n",
      "  'ANNOUNCED': 970,\n",
      "  'ANTHEM': 971,\n",
      "  'ANTI-CATHOLIC': 972,\n",
      "  'ANTI-DEFENSE': 973,\n",
      "  'ANY': 974,\n",
      "  'ANYMORE': 975,\n",
      "  'ANYONE': 976,\n",
      "  'ANYTHING': 977,\n",
      "  'AP': 978,\n",
      "  'AP-NORC': 979,\n",
      "  'APEC': 980,\n",
      "  'APEC2017': 981,\n",
      "  'APOLOGIZE': 982,\n",
      "  'APP': 983,\n",
      "  'APPOINTMENT': 984,\n",
      "  'APPREHEND': 985,\n",
      "  'APPROVAL': 986,\n",
      "  'APPROVE': 987,\n",
      "  'AP_Politics': 988,\n",
      "  'AR': 989,\n",
      "  'ARE': 990,\n",
      "  'ARG': 991,\n",
      "  'ARIZONA': 992,\n",
      "  'ARMY': 993,\n",
      "  'AROUND': 994,\n",
      "  'ARREST': 995,\n",
      "  'ARRIVED': 996,\n",
      "  'ARSenMissyIrvin': 997,\n",
      "  'AS': 998,\n",
      "  'ASAP': 999,\n",
      "  'ASEAN50': 1000,\n",
      "  'ASEANSummit': 1001,\n",
      "  'ASIA': 1002,\n",
      "  'AT': 1003,\n",
      "  'AT&amp;T': 1004,\n",
      "  'AT&amp;T-Time': 1005,\n",
      "  'ATFD17': 1006,\n",
      "  'ATTACKS': 1007,\n",
      "  'ATTN': 1008,\n",
      "  'ATTORNEYS': 1009,\n",
      "  'AUSTIN': 1010,\n",
      "  'AVOID': 1011,\n",
      "  'AWARDS': 1012,\n",
      "  'AWAY': 1013,\n",
      "  'AWEIGH': 1014,\n",
      "  'AWESOME': 1015,\n",
      "  'AWOL': 1016,\n",
      "  'AYA': 1017,\n",
      "  'AZ': 1018,\n",
      "  'AZ08': 1019,\n",
      "  'AZPrimary': 1020,\n",
      "  'AZTRUMPTRAIN': 1021,\n",
      "  'Abbas': 1022,\n",
      "  'Abbott': 1023,\n",
      "  'Abdeslam': 1024,\n",
      "  'Abdul': 1025,\n",
      "  'Abdullah': 1026,\n",
      "  'Abe': 1027,\n",
      "  'AbeShinzo': 1028,\n",
      "  'Abedin': 1029,\n",
      "  'Aberdeen': 1030,\n",
      "  'Abingdon': 1031,\n",
      "  'AbolishICE': 1032,\n",
      "  'Abortion': 1033,\n",
      "  'About': 1034,\n",
      "  'Abraham': 1035,\n",
      "  'Abrams': 1036,\n",
      "  'Abramson': 1037,\n",
      "  'Absentee': 1038,\n",
      "  'Abuse': 1039,\n",
      "  'Academy': 1040,\n",
      "  'Access': 1041,\n",
      "  'Accomplished': 1042,\n",
      "  'Accord': 1043,\n",
      "  'According': 1044,\n",
      "  'Account': 1045,\n",
      "  'Accountability': 1046,\n",
      "  'Accusation': 1047,\n",
      "  'Accusations': 1048,\n",
      "  'Accuser': 1049,\n",
      "  'Acosta': 1050,\n",
      "  'Across': 1051,\n",
      "  'Act': 1052,\n",
      "  'Act?': 1053,\n",
      "  'Acting': 1054,\n",
      "  'Action': 1055,\n",
      "  'Actions': 1056,\n",
      "  'ActiveDuty': 1057,\n",
      "  'Activism': 1058,\n",
      "  'Activists': 1059,\n",
      "  'Actress': 1060,\n",
      "  'Actually': 1061,\n",
      "  'Act…': 1062,\n",
      "  'Ad': 1063,\n",
      "  'Adam': 1064,\n",
      "  'AdamSchiff': 1065,\n",
      "  'Adams': 1066,\n",
      "  'Add': 1067,\n",
      "  'Added': 1068,\n",
      "  'Additional': 1069,\n",
      "  'Additionally': 1070,\n",
      "  'Address': 1071,\n",
      "  'Address-': 1072,\n",
      "  'AddressJoin': 1073,\n",
      "  'Addressing': 1074,\n",
      "  'Address🇺🇸': 1075,\n",
      "  'Adds': 1076,\n",
      "  'Adelson': 1077,\n",
      "  'Adjusting': 1078,\n",
      "  'Admin': 1079,\n",
      "  'Administration': 1080,\n",
      "  'Administration?': 1081,\n",
      "  'Administrations': 1082,\n",
      "  'Administrator': 1083,\n",
      "  'Admini…': 1084,\n",
      "  'Admins': 1085,\n",
      "  'Admiral': 1086,\n",
      "  'Admiral/Doctor': 1087,\n",
      "  'Adolph': 1088,\n",
      "  'AdrianaCohen16': 1089,\n",
      "  'Adrienne': 1090,\n",
      "  'Ads': 1091,\n",
      "  'Advantage': 1092,\n",
      "  'Advice': 1093,\n",
      "  'Adviser': 1094,\n",
      "  'Advisers': 1095,\n",
      "  'Advisor': 1096,\n",
      "  'Advisory': 1097,\n",
      "  'Aerial': 1098,\n",
      "  'Aetna': 1099,\n",
      "  'Affairs': 1100,\n",
      "  'Affection': 1101,\n",
      "  'Affordable': 1102,\n",
      "  'AfghanStrategy': 1103,\n",
      "  'Afghanistan': 1104,\n",
      "  'Afghans': 1105,\n",
      "  'Africa': 1106,\n",
      "  'African': 1107,\n",
      "  'African-American': 1108,\n",
      "  'African-Americans': 1109,\n",
      "  'African/American': 1110,\n",
      "  'AfricanAmericanHistoryMonth': 1111,\n",
      "  'After': 1112,\n",
      "  'Ag': 1113,\n",
      "  'Again': 1114,\n",
      "  'Again-': 1115,\n",
      "  'Against': 1116,\n",
      "  'Age': 1117,\n",
      "  'Agencies': 1118,\n",
      "  'Agency': 1119,\n",
      "  'Agenda': 1120,\n",
      "  'Agent': 1121,\n",
      "  'Agent/Lover': 1122,\n",
      "  'Agents': 1123,\n",
      "  'Aggressively': 1124,\n",
      "  'Agitators': 1125,\n",
      "  'Agree': 1126,\n",
      "  'Agreed': 1127,\n",
      "  'Agreement': 1128,\n",
      "  'Agreements': 1129,\n",
      "  'Agricultural': 1130,\n",
      "  'Agriculture': 1131,\n",
      "  'Aid': 1132,\n",
      "  'Aided': 1133,\n",
      "  'Aides': 1134,\n",
      "  'Ailes': 1135,\n",
      "  'Ailes?': 1136,\n",
      "  'Ailsa': 1137,\n",
      "  'Ainsley': 1138,\n",
      "  'Air': 1139,\n",
      "  'AirForce': 1140,\n",
      "  'Airborne': 1141,\n",
      "  'Aircraft': 1142,\n",
      "  'Aircrews': 1143,\n",
      "  'Aires': 1144,\n",
      "  'Airlines': 1145,\n",
      "  'Airplane': 1146,\n",
      "  'Airplanes': 1147,\n",
      "  'Airport': 1148,\n",
      "  'Airports': 1149,\n",
      "  'Akbar': 1150,\n",
      "  'Akron': 1151,\n",
      "  'Al': 1152,\n",
      "  'Al-Baghdadi': 1153,\n",
      "  'Al-Shabaab': 1154,\n",
      "  'Alabama': 1155,\n",
      "  'AlabamaNG': 1156,\n",
      "  'AlabamaTickets': 1157,\n",
      "  'Alain_Berset': 1158,\n",
      "  'Alan': 1159,\n",
      "  'AlanDersh': 1160,\n",
      "  'Alaska': 1161,\n",
      "  'Albany': 1162,\n",
      "  'Albert': 1163,\n",
      "  'Albuquerque': 1164,\n",
      "  'Aldridge': 1165,\n",
      "  'Alec': 1166,\n",
      "  'Alejandro': 1167,\n",
      "  'Alene': 1168,\n",
      "  'Alert': 1169,\n",
      "  'Alex': 1170,\n",
      "  'AlexNightrasor': 1171,\n",
      "  'Alexander': 1172,\n",
      "  'Alexis': 1173,\n",
      "  'Alfonse': 1174,\n",
      "  'Ali': 1175,\n",
      "  'Alice': 1176,\n",
      "  'Alicia': 1177,\n",
      "  'Alien': 1178,\n",
      "  'Aliens': 1179,\n",
      "  'AlisonForKY': 1180,\n",
      "  'AlisynCamerota': 1181,\n",
      "  'All': 1182,\n",
      "  'All-Time': 1183,\n",
      "  'Allah': 1184,\n",
      "  'Allegations': 1185,\n",
      "  'Alleged': 1186,\n",
      "  'Allegiance': 1187,\n",
      "  'AllegrettiVicki': 1188,\n",
      "  'Allen': 1189,\n",
      "  'AllenWest': 1190,\n",
      "  'Allied': 1191,\n",
      "  'Allies': 1192,\n",
      "  'Allis': 1193,\n",
      "  'Allowed': 1194,\n",
      "  'Ally': 1195,\n",
      "  'Almost': 1196,\n",
      "  'Aloha': 1197,\n",
      "  'Along': 1198,\n",
      "  'Already': 1199,\n",
      "  'AlsisiOfficial': 1200,\n",
      "  'Also': 1201,\n",
      "  'Although': 1202,\n",
      "  'Aluminum': 1203,\n",
      "  'Alvarez/Khan': 1204,\n",
      "  'Always': 1205,\n",
      "  'AlwaysTrump': 1206,\n",
      "  'Am': 1207,\n",
      "  'AmFamChamp': 1208,\n",
      "  'AmFree': 1209,\n",
      "  'Amazing': 1210,\n",
      "  'Amazingly': 1211,\n",
      "  'Amazon': 1212,\n",
      "  'AmazonWashingtonPost': 1213,\n",
      "  'Amazons': 1214,\n",
      "  'Amb': 1215,\n",
      "  'AmbJohnBolton': 1216,\n",
      "  'Ambassador': 1217,\n",
      "  'Ambassadors': 1218,\n",
      "  'Ambassado…': 1219,\n",
      "  'Ambridge': 1220,\n",
      "  'Ambs......': 1221,\n",
      "  'Amendmen': 1222,\n",
      "  'Amendment': 1223,\n",
      "  'Amendment-and': 1224,\n",
      "  'AmerIcan32': 1225,\n",
      "  'Amercan': 1226,\n",
      "  'America': 1227,\n",
      "  'America-': 1228,\n",
      "  'America-First': 1229,\n",
      "  'America=$20': 1230,\n",
      "  'America?': 1231,\n",
      "  'AmericaExecutive': 1232,\n",
      "  'AmericaFIRST': 1233,\n",
      "  'AmericaFirst': 1234,\n",
      "  'AmericaFirst#': 1235,\n",
      "  'AmericaFirst-': 1236,\n",
      "  'AmericaFirstPol': 1237,\n",
      "  'AmericaFirstVideo': 1238,\n",
      "  'AmericaFirst[URL]': 1239,\n",
      "  'AmericaFirst…': 1240,\n",
      "  'AmericaFirst🇺🇸': 1241,\n",
      "  'AmericaFirst🇺🇸#': 1242,\n",
      "  'AmericaFirst🇺🇸➡️…': 1243,\n",
      "  'AmericaGreatAgain': 1244,\n",
      "  'American': 1245,\n",
      "  'AmericanAsPie': 1246,\n",
      "  'AmericanHeroes': 1247,\n",
      "  'AmericanLegion': 1248,\n",
      "  'AmericanPatientsFirst': 1249,\n",
      "  'AmericanSamoa': 1250,\n",
      "  'AmericanUnity': 1251,\n",
      "  'Americanism': 1252,\n",
      "  'Americans': 1253,\n",
      "  'Americans?': 1254,\n",
      "  'Americans🇺🇸#': 1255,\n",
      "  'American…': 1256,\n",
      "  'Americas': 1257,\n",
      "  'Americas....': 1258,\n",
      "  'AmericasMerkel': 1259,\n",
      "  'America—she': 1260,\n",
      "  'America…': 1261,\n",
      "  'America🇺🇸': 1262,\n",
      "  'America🇺🇸FOUR': 1263,\n",
      "  'Americ…': 1264,\n",
      "  'Ameri…': 1265,\n",
      "  'Ame…': 1266,\n",
      "  'Amgen': 1267,\n",
      "  'Amir': 1268,\n",
      "  'Amnesty': 1269,\n",
      "  'Among': 1270,\n",
      "  'Amy': 1271,\n",
      "  'AmyKremer': 1272,\n",
      "  'An': 1273,\n",
      "  'Anaheim': 1274,\n",
      "  'Analyst': 1275,\n",
      "  'Analysts': 1276,\n",
      "  'Anchor': 1277,\n",
      "  'Anchored': 1278,\n",
      "  'And': 1279,\n",
      "  'Andeavor': 1280,\n",
      "  'Anderson': 1281,\n",
      "  'AndersonCooper': 1282,\n",
      "  'AndreBauer': 1283,\n",
      "  'AndreaTantaros-': 1284,\n",
      "  'Andres': 1285,\n",
      "  'Andrew': 1286,\n",
      "  'AndrewGillum': 1287,\n",
      "  'Andrews': 1288,\n",
      "  'Andrews_JBA': 1289,\n",
      "  'Andrzej': 1290,\n",
      "  'Andy': 1291,\n",
      "  'AndyPuzder': 1292,\n",
      "  'AngPiazza': 1293,\n",
      "  'Angel': 1294,\n",
      "  'Angela': 1295,\n",
      "  'Angeles': 1296,\n",
      "  'Anger': 1297,\n",
      "  'Angie': 1298,\n",
      "  'AngieSteinberg': 1299,\n",
      "  'Angry': 1300,\n",
      "  'Animal': 1301,\n",
      "  'Animals': 1302,\n",
      "  'Ann': 1303,\n",
      "  'AnnCoulter': 1304,\n",
      "  'AnnCoulters': 1305,\n",
      "  'Anna': 1306,\n",
      "  'Anna_Giaritelli': 1307,\n",
      "  'Annapolis': 1308,\n",
      "  'AnneBellar': 1309,\n",
      "  'AnnesLimo': 1310,\n",
      "  'AnnetteJeanne': 1311,\n",
      "  'Annies': 1312,\n",
      "  'Anniv': 1313,\n",
      "  'Anniversary': 1314,\n",
      "  'Announcement': 1315,\n",
      "  'Announces': 1316,\n",
      "  'Annual': 1317,\n",
      "  'Another': 1318,\n",
      "  'Answers': 1319,\n",
      "  'Anthem': 1320,\n",
      "  'Anthem-RESPECT': 1321,\n",
      "  'Anthem?…': 1322,\n",
      "  'Anthony': 1323,\n",
      "  'AnthonyWeiner': 1324,\n",
      "  'Anti-': 1325,\n",
      "  'Anti-Catholic': 1326,\n",
      "  'Anti-Israel': 1327,\n",
      "  'Anti-Second': 1328,\n",
      "  'Anti-Semitic': 1329,\n",
      "  'Anti-Semitism': 1330,\n",
      "  'Anti-Trump': 1331,\n",
      "  'Anti-Trust': 1332,\n",
      "  'Anti-Women': 1333,\n",
      "  'Anti-climbing': 1334,\n",
      "  'Anticipated': 1335,\n",
      "  'Antiquities': 1336,\n",
      "  'Antitrust': 1337,\n",
      "  'Anton': 1338,\n",
      "  'Antonin': 1339,\n",
      "  'AntonioGuterres': 1340,\n",
      "  'António': 1341,\n",
      "  'Any': 1342,\n",
      "  'Anybody': 1343,\n",
      "  'Anyone': 1344,\n",
      "  'AnyoneTennis': 1345,\n",
      "  'Anything': 1346,\n",
      "  'Anytime': 1347,\n",
      "  'Any…': 1348,\n",
      "  'Apologize': 1349,\n",
      "  'Apologize?': 1350,\n",
      "  'App': 1351,\n",
      "  'Appeals': 1352,\n",
      "  'Apple': 1353,\n",
      "  'Appleton': 1354,\n",
      "  'Application': 1355,\n",
      "  'Appointment': 1356,\n",
      "  'Appointments': 1357,\n",
      "  'Appreciate': 1358,\n",
      "  'Appreciation': 1359,\n",
      "  'Apprehension': 1360,\n",
      "  'Apprentic': 1361,\n",
      "  'Apprentice': 1362,\n",
      "  'Approval': 1363,\n",
      "  'Approvals': 1364,\n",
      "  'Approve': 1365,\n",
      "  'Approves': 1366,\n",
      "  'April': 1367,\n",
      "  'AprilLaJune': 1368,\n",
      "  'Arab': 1369,\n",
      "  'Arabella': 1370,\n",
      "  'Arabia': 1371,\n",
      "  'Arabian': 1372,\n",
      "  'Aramco': 1373,\n",
      "  'Arbitration': 1374,\n",
      "  'Architect': 1375,\n",
      "  'Are': 1376,\n",
      "  'Area': 1377,\n",
      "  'Arena': 1378,\n",
      "  'Arena-': 1379,\n",
      "  'Aretha': 1380,\n",
      "  'Argentina': 1381,\n",
      "  'Argentine': 1382,\n",
      "  'AriFleischer': 1383,\n",
      "  'Arizona': 1384,\n",
      "  'Arizona-': 1385,\n",
      "  'ArizonaPrimary': 1386,\n",
      "  'Arkansas': 1387,\n",
      "  'Arlene': 1388,\n",
      "  'Arlington': 1389,\n",
      "  'ArlingtonNatl': 1390,\n",
      "  'Armed': 1391,\n",
      "  'ArmedForcesDay': 1392,\n",
      "  'Armistice': 1393,\n",
      "  'Arms': 1394,\n",
      "  'Army': 1395,\n",
      "  'Army-Navy': 1396,\n",
      "  'ArmyNavyGame': 1397,\n",
      "  'ArmyNavyGame🇺🇸': 1398,\n",
      "  'ArmyWP_Football': 1399,\n",
      "  'Arnold': 1400,\n",
      "  'Arpaio': 1401,\n",
      "  'Arrested': 1402,\n",
      "  'Arrington': 1403,\n",
      "  'Arrived': 1404,\n",
      "  'Arriving': 1405,\n",
      "  'Art': 1406,\n",
      "  'Arthur': 1407,\n",
      "  'Article': 1408,\n",
      "  'Artie': 1409,\n",
      "  'As': 1410,\n",
      "  'Asa': 1411,\n",
      "  'AsaHutchinson': 1412,\n",
      "  'Asad': 1413,\n",
      "  'Asheville': 1414,\n",
      "  'Ashley': 1415,\n",
      "  'AshleyEdam': 1416,\n",
      "  'Ashraf': 1417,\n",
      "  'Asia': 1418,\n",
      "  'Asian': 1419,\n",
      "  'Asians': 1420,\n",
      "  'Ask': 1421,\n",
      "  'Asked': 1422,\n",
      "  'Asking': 1423,\n",
      "  'Asman': 1424,\n",
      "  'Aspen': 1425,\n",
      "  'Assad': 1426,\n",
      "  'Assad.....': 1427,\n",
      "  'Assange': 1428,\n",
      "  'Assembly': 1429,\n",
      "  'Assemblyman': 1430,\n",
      "  'Assessment......': 1431,\n",
      "  'Assistance': 1432,\n",
      "  'Assistant': 1433,\n",
      "  'Assoc': 1434,\n",
      "  'Associate': 1435,\n",
      "  'Associates': 1436,\n",
      "  'Association': 1437,\n",
      "  'Associations': 1438,\n",
      "  'Associat…': 1439,\n",
      "  'Assuming': 1440,\n",
      "  'Astonishing': 1441,\n",
      "  'AstroPeggy': 1442,\n",
      "  'Astros': 1443,\n",
      "  'Asylum': 1444,\n",
      "  'At': 1445,\n",
      "  'Atlanta': 1446,\n",
      "  'Atlantas': 1447,\n",
      "  'Atlantic': 1448,\n",
      "  'Attack': 1449,\n",
      "  'Attacked': 1450,\n",
      "  'Attacks': 1451,\n",
      "  'Attempted': 1452,\n",
      "  'Attendance': 1453,\n",
      "  'Attending': 1454,\n",
      "  'Attends': 1455,\n",
      "  'Attkisson': 1456,\n",
      "  'Attorney': 1457,\n",
      "  'Attorneys': 1458,\n",
      "  'Attorney–client': 1459,\n",
      "  'Audience': 1460,\n",
      "  'Aug': 1461,\n",
      "  'August': 1462,\n",
      "  'August...': 1463,\n",
      "  'Augusta': 1464,\n",
      "  'Augustine': 1465,\n",
      "  'August…': 1466,\n",
      "  'Aura': 1467,\n",
      "  'Aurora': 1468,\n",
      "  'Ausbiz': 1469,\n",
      "  'Austin': 1470,\n",
      "  'Australia': 1471,\n",
      "  'Australian': 1472,\n",
      "  'Australians': 1473,\n",
      "  'Authorities': 1474,\n",
      "  'Authority': 1475,\n",
      "  'Authorization': 1476,\n",
      "  'Autism': 1477,\n",
      "  'AutismAwarenessDay': 1478,\n",
      "  'Auto': 1479,\n",
      "  'Autoworkers': 1480,\n",
      "  'Available': 1481,\n",
      "  'Avenatti': 1482,\n",
      "  'Average': 1483,\n",
      "  'Aviation': 1484,\n",
      "  'Aviv': 1485,\n",
      "  'Avoid': 1486,\n",
      "  'Avoided': 1487,\n",
      "  'Aw-shucks': 1488,\n",
      "  'Awada': 1489,\n",
      "  'Awan': 1490,\n",
      "  'Award': 1491,\n",
      "  'Awards': 1492,\n",
      "  'Awareness': 1493,\n",
      "  'Away': 1494,\n",
      "  'Aya': 1495,\n",
      "  'Ayers': 1496,\n",
      "  'AynsFriend': 1497,\n",
      "  'Azar': 1498,\n",
      "  'A…': 1499,\n",
      "  'B' : 1500,\n",
      "  'B+': 1501,\n",
      "  'B-1B': 1502,\n",
      "  'BACK': 1503,\n",
      "  'BAD': 1504,\n",
      "  'BADLY': 1505,\n",
      "  'BAILOUTS': 1506,\n",
      "  'BAN': 1507,\n",
      "  'BANNING': 1508,\n",
      "  'BARACK': 1509,\n",
      "  'BARRIERS': 1510,\n",
      "  'BASE': 1511,\n",
      "  'BASED': 1512,\n",
      "  'BC': 1513,\n",
      "  'BE': 1514,\n",
      "  'BEAT': 1515,\n",
      "  'BECAUSE': 1516,\n",
      "  'BECK': 1517,\n",
      "  'BEEN': 1518,\n",
      "  'BEFORE': 1519,\n",
      "  'BEG': 1520,\n",
      "  'BEGINS': 1521,\n",
      "  'BELIEVE': 1522,\n",
      "  'BENCH': 1523,\n",
      "  'BEST': 1524,\n",
      "  'BETTER': 1525,\n",
      "  'BETWEEN': 1526,\n",
      "  'BEWARE': 1527,\n",
      "  'BIG': 1528,\n",
      "  'BIGGER': 1529,\n",
      "  'BIGGEST': 1530,\n",
      "  'BIGOTRY': 1531,\n",
      "  'BILATERAL': 1532,\n",
      "  'BILL': 1533,\n",
      "  'BILLION': 1534,\n",
      "  'BILLION/yr': 1535,\n",
      "  'BILLIONS': 1536,\n",
      "  'BILLS': 1537,\n",
      "  'BILLY': 1538,\n",
      "  'BIRTHDAY': 1539,\n",
      "  'BLAME': 1540,\n",
      "  'BLANK': 1541,\n",
      "  'BLATANTLY': 1542,\n",
      "  'BLESS': 1543,\n",
      "  'BLESSINGS': 1544,\n",
      "  'BLEW': 1545,\n",
      "  'BLOOD': 1546,\n",
      "  'BLUE': 1547,\n",
      "  'BMW': 1548,\n",
      "  'BOLD': 1549,\n",
      "  'BOMB': 1550,\n",
      "  'BOMBING': 1551,\n",
      "  'BOMBSHELL': 1552,\n",
      "  'BOMBSHELLS': 1553,\n",
      "  'BOOK': 1554,\n",
      "  'BOOM': 1555,\n",
      "  'BOOMING': 1556,\n",
      "  'BORDER': 1557,\n",
      "  'BORDERS': 1558,\n",
      "  'BOTH': 1559,\n",
      "  'BOYCOTT': 1560,\n",
      "  'BOYS': 1561,\n",
      "  'BP': 1562,\n",
      "  'BRAINWASHED': 1563,\n",
      "  'BRAVE': 1564,\n",
      "  'BREAKDOWN': 1565,\n",
      "  'BREAKING': 1566,\n",
      "  'BRETT': 1567,\n",
      "  'BREXIT': 1568,\n",
      "  'BRING': 1569,\n",
      "  'BROAD-SHOULDERED': 1570,\n",
      "  'BROKE': 1571,\n",
      "  'BROKEN': 1572,\n",
      "  'BRUNSON': 1573,\n",
      "  'BS': 1574,\n",
      "  'BUILD': 1575,\n",
      "  'BUILDING': 1576,\n",
      "  'BUILT': 1577,\n",
      "  'BUMP': 1578,\n",
      "  'BURN': 1579,\n",
      "  'BUSINESS': 1580,\n",
      "  'BUST': 1581,\n",
      "  'BUSTED': 1582,\n",
      "  'BUT': 1583,\n",
      "  'BUY': 1584,\n",
      "  'BY': 1585,\n",
      "  'BYE-BYE': 1586,\n",
      "  'Babies': 1587,\n",
      "  'Back': 1588,\n",
      "  'Backbone': 1589,\n",
      "  'Background': 1590,\n",
      "  'Bad': 1591,\n",
      "  'Bader': 1592,\n",
      "  'Badly': 1593,\n",
      "  'Baghdad': 1594,\n",
      "  'Bahrain': 1595,\n",
      "  'Bailey': 1596,\n",
      "  'Baja': 1597,\n",
      "  'Bakari': 1598,\n",
      "  'Baker': 1599,\n",
      "  'Balderson': 1600,\n",
      "  'Baldersons': 1601,\n",
      "  'Baldwin': 1602,\n",
      "  'Ball': 1603,\n",
      "  'Ballard': 1604,\n",
      "  'Ballistic': 1605,\n",
      "  'Ballot': 1606,\n",
      "  'Ballots': 1607,\n",
      "  'BalticSummit': 1608,\n",
      "  'Baltimore': 1609,\n",
      "  'Ban': 1610,\n",
      "  'Band': 1611,\n",
      "  'Bangladesh': 1612,\n",
      "  'Bangor': 1613,\n",
      "  'Bank': 1614,\n",
      "  'Bannon': 1615,\n",
      "  'Bar': 1616,\n",
      "  'Barack': 1617,\n",
      "  'BarackObama': 1618,\n",
      "  'Barbara': 1619,\n",
      "  'Barbaro': 1620,\n",
      "  'Barcelona': 1621,\n",
      "  'Barletta': 1622,\n",
      "  'Barr': 1623,\n",
      "  'Barra': 1624,\n",
      "  'Barrack': 1625,\n",
      "  'Barracks': 1626,\n",
      "  'Barrasso': 1627,\n",
      "  'Barrier': 1628,\n",
      "  'Barrier?': 1629,\n",
      "  'Barriers': 1630,\n",
      "  'Barron': 1631,\n",
      "  'BarronG510': 1632,\n",
      "  'Barry': 1633,\n",
      "  'Bartiromo': 1634,\n",
      "  'Base': 1635,\n",
      "  'Baseball': 1636,\n",
      "  'Based': 1637,\n",
      "  'Basel': 1638,\n",
      "  'BasementDwellers': 1639,\n",
      "  'Bashar': 1640,\n",
      "  'Basically': 1641,\n",
      "  'Basketball': 1642,\n",
      "  'Bastille': 1643,\n",
      "  'BastilleDay': 1644,\n",
      "  'Bates': 1645,\n",
      "  'Batman': 1646,\n",
      "  'Baton': 1647,\n",
      "  'Battalion': 1648,\n",
      "  'Battleground': 1649,\n",
      "  'Bay': 1650,\n",
      "  'Bay-': 1651,\n",
      "  'Bayer': 1652,\n",
      "  'Be': 1653,\n",
      "  'BeBest': 1654,\n",
      "  'Beach': 1655,\n",
      "  'Bean': 1656,\n",
      "  'Bear': 1657,\n",
      "  'Bears': 1658,\n",
      "  'Beat': 1659,\n",
      "  'Beautiful': 1660,\n",
      "  'Because': 1661,\n",
      "  'Beck': 1662,\n",
      "  'Become': 1663,\n",
      "  'Becoming': 1664,\n",
      "  'Bedford': 1665,\n",
      "  'Bedminster': 1666,\n",
      "  'Bee': 1667,\n",
      "  'Been': 1668,\n",
      "  'Before': 1669,\n",
      "  'Begala': 1670,\n",
      "  'Begged': 1671,\n",
      "  'Beginning': 1672,\n",
      "  'Behind': 1673,\n",
      "  'Beijing': 1674,\n",
      "  'Being': 1675,\n",
      "  'Beirut': 1676,\n",
      "  'Belgium': 1677,\n",
      "  'Belichick': 1678,\n",
      "  'Believe': 1679,\n",
      "  'Belizediver88': 1680,\n",
      "  'Below': 1681,\n",
      "  'Belt': 1682,\n",
      "  'Bel…': 1683,\n",
      "  'Bemoan': 1684,\n",
      "  'Ben': 1685,\n",
      "  'BenSasse': 1686,\n",
      "  'Bend': 1687,\n",
      "  'Benefactor': 1688,\n",
      "  'Benghazi': 1689,\n",
      "  'Benghazi?': 1690,\n",
      "  'Benjamin': 1691,\n",
      "  'Bennett': 1692,\n",
      "  'Bens': 1693,\n",
      "  'Bergdahl': 1694,\n",
      "  'Berglund': 1695,\n",
      "  'Berkeley': 1696,\n",
      "  'Berlin': 1697,\n",
      "  'Bernhardt': 1698,\n",
      "  'Bernie': 1699,\n",
      "  'BernieSanders': 1700,\n",
      "  'Bernies': 1701,\n",
      "  'Berrien': 1702,\n",
      "  'BertShad': 1703,\n",
      "  'Besides': 1704,\n",
      "  'Best': 1705,\n",
      "  'Bet22325450ste': 1706,\n",
      "  'Bethpage': 1707,\n",
      "  'Beto': 1708,\n",
      "  'Betrayed': 1709,\n",
      "  'BetsyDeVos': 1710,\n",
      "  'BetsyDeVosED': 1711,\n",
      "  'Better': 1712,\n",
      "  'Beverly': 1713,\n",
      "  'Beware': 1714,\n",
      "  'BeyondZeroKenya': 1715,\n",
      "  'Bezos': 1716,\n",
      "  'Bias': 1717,\n",
      "  'Bias?': 1718,\n",
      "  'Biased': 1719,\n",
      "  'Bible': 1720,\n",
      "  'Biden': 1721,\n",
      "  'Bidens': 1722,\n",
      "  'Big': 1723,\n",
      "  'Big-game': 1724,\n",
      "  'BigLeageTruth': 1725,\n",
      "  'BigLeagueTruth': 1726,\n",
      "  'BigLeagueTruth#': 1727,\n",
      "  'BigLeagueTruthTime': 1728,\n",
      "  'BigLeagueTruth[URL]': 1729,\n",
      "  'BigLeagueTruth…': 1730,\n",
      "  'BigLeagueTrut…': 1731,\n",
      "  'BigLeague…': 1732,\n",
      "  'BigLeagu…': 1733,\n",
      "  'BigLeag…': 1734,\n",
      "  'Bigger': 1735,\n",
      "  'Biggest': 1736,\n",
      "  'Biggs': 1737,\n",
      "  'Bighorn': 1738,\n",
      "  'Bikers': 1739,\n",
      "  'BikersForTrump': 1740,\n",
      "  'Bil': 1741,\n",
      "  'Bilateral': 1742,\n",
      "  'Bill': 1743,\n",
      "  'BillClinton': 1744,\n",
      "  'BillGates': 1745,\n",
      "  'BillHemmer': 1746,\n",
      "  'BillKristol': 1747,\n",
      "  'Billings': 1748,\n",
      "  'Billion': 1749,\n",
      "  'Billion/year': 1750,\n",
      "  'Billions': 1751,\n",
      "  'Bills': 1752,\n",
      "  'Billy': 1753,\n",
      "  'BillyGraham': 1754,\n",
      "  'BillyJoel-': 1755,\n",
      "  'BillyNungesser': 1756,\n",
      "  'Billygrahams': 1757,\n",
      "  'Bin': 1758,\n",
      "  'Binion': 1759,\n",
      "  'Biodefense': 1760,\n",
      "  'Bipartisan': 1761,\n",
      "  'BirgitOlsen1': 1762,\n",
      "  'Birthday': 1763,\n",
      "  'Birthright': 1764,\n",
      "  'Bishop': 1765,\n",
      "  'Black': 1766,\n",
      "  'BlackMenForBernie': 1767,\n",
      "  'Blackan': 1768,\n",
      "  'Blackburn': 1769,\n",
      "  'Blacks': 1770,\n",
      "  'BlacksForTrump': 1771,\n",
      "  'Blagojevich': 1772,\n",
      "  'Blah': 1773,\n",
      "  'Blair': 1774,\n",
      "  'Blakeman': 1775,\n",
      "  'Blame': 1776,\n",
      "  'Blaming': 1777,\n",
      "  'Blankenship': 1778,\n",
      "  'Blasio': 1779,\n",
      "  'Blast': 1780,\n",
      "  'Blasts': 1781,\n",
      "  'Blaze': 1782,\n",
      "  'Bless': 1783,\n",
      "  'Blew': 1784,\n",
      "  'Blimp': 1785,\n",
      "  'Block': 1786,\n",
      "  'Bloomberg': 1787,\n",
      "  'Blowout': 1788,\n",
      "  'Blue': 1789,\n",
      "  'Bluegrass…': 1790,\n",
      "  'Blueprint': 1791,\n",
      "  'Bluffs': 1792,\n",
      "  'Blumenthal': 1793,\n",
      "  'Board': 1794,\n",
      "  'Boarder': 1795,\n",
      "  'Boards': 1796,\n",
      "  'Bob': 1797,\n",
      "  'Bobby': 1798,\n",
      "  'Boca': 1799,\n",
      "  'Boeing': 1800,\n",
      "  'Bolling': 1801,\n",
      "  'Bolsonaro': 1802,\n",
      "  'Bolt': 1803,\n",
      "  'Bolton': 1804,\n",
      "  'Bomb': 1805,\n",
      "  'Bombs': 1806,\n",
      "  'Bombshell': 1807,\n",
      "  'Bonfiredesigns': 1808,\n",
      "  'Bongino': 1809,\n",
      "  'Bonus': 1810,\n",
      "  'Book': 1811,\n",
      "  'Booker': 1812,\n",
      "  'Boom': 1813,\n",
      "  'Borde': 1814,\n",
      "  'Border': 1815,\n",
      "  'Border......': 1816,\n",
      "  'BorderControl': 1817,\n",
      "  'Borders': 1818,\n",
      "  'Border…': 1819,\n",
      "  'Boring': 1820,\n",
      "  'Borisep': 1821,\n",
      "  'BornToBeGOP': 1822,\n",
      "  'Bossie': 1823,\n",
      "  'Boston': 1824,\n",
      "  'Both': 1825,\n",
      "  'Bought': 1826,\n",
      "  'Bowden': 1827,\n",
      "  'Bowl': 1828,\n",
      "  'Box': 1829,\n",
      "  'Boy': 1830,\n",
      "  'Boycott': 1831,\n",
      "  'Boynton': 1832,\n",
      "  'Boys': 1833,\n",
      "  'Bozo': 1834,\n",
      "  'Brad': 1835,\n",
      "  'BradCross4': 1836,\n",
      "  'BradThor': 1837,\n",
      "  'Brady': 1838,\n",
      "  'Brainykid2010': 1839,\n",
      "  'Branch': 1840,\n",
      "  'Brandon': 1841,\n",
      "  'BrandonSawyer84': 1842,\n",
      "  'Braun': 1843,\n",
      "  'Braun4Indiana': 1844,\n",
      "  'Brave': 1845,\n",
      "  'BrazielCarol': 1846,\n",
      "  'Brazil': 1847,\n",
      "  'Brazile': 1848,\n",
      "  'Brazilian': 1849,\n",
      "  'BrazoriaCounty': 1850,\n",
      "  'Breakfast': 1851,\n",
      "  'Breaking': 1852,\n",
      "  'BreakingNews': 1853,\n",
      "  'Breckenridge': 1854,\n",
      "  'Brees': 1855,\n",
      "  'Breitbart': 1856,\n",
      "  'BreitbartNew': 1857,\n",
      "  'BreitbartNews': 1858,\n",
      "  'Brenda': 1859,\n",
      "  'Brennan': 1860,\n",
      "  'Brennan...': 1861,\n",
      "  'Brennans': 1862,\n",
      "  'BrentBozell': 1863,\n",
      "  'BrentSanfordND': 1864,\n",
      "  'BretBaier': 1865,\n",
      "  'BretEastonEllis': 1866,\n",
      "  'Brett': 1867,\n",
      "  'Brewer': 1868,\n",
      "  'Brexit': 1869,\n",
      "  'Brian': 1870,\n",
      "  'BrianKempGA': 1871,\n",
      "  'Bribery': 1872,\n",
      "  'Bridge': 1873,\n",
      "  'Bridgeport': 1874,\n",
      "  'Briefed': 1875,\n",
      "  'Briefing': 1876,\n",
      "  'Briefings': 1877,\n",
      "  'Brigid': 1878,\n",
      "  'Brigitte': 1879,\n",
      "  'Brilliant': 1880,\n",
      "  'Bring': 1881,\n",
      "  'Bringing': 1882,\n",
      "  'Brit': 1883,\n",
      "  'Britain': 1884,\n",
      "  'British': 1885,\n",
      "  'Britt': 1886,\n",
      "  'Broadcast': 1887,\n",
      "  'Broadcasting': 1888,\n",
      "  'Broadcom': 1889,\n",
      "  'Broadcoms': 1890,\n",
      "  'Broaddrick': 1891,\n",
      "  'Broadway': 1892,\n",
      "  'Brock': 1893,\n",
      "  'Brody': 1894,\n",
      "  'Broke': 1895,\n",
      "  'Broken': 1896,\n",
      "  'Brooks': 1897,\n",
      "  'Brother': 1898,\n",
      "  'Brothers': 1899,\n",
      "  'Brought': 1900,\n",
      "  'Broward': 1901,\n",
      "  'Brown': 1902,\n",
      "  'Browns': 1903,\n",
      "  'Bruce': 1904,\n",
      "  'BrucePoliquin': 1905,\n",
      "  'Bruno': 1906,\n",
      "  'Brunson': 1907,\n",
      "  'Brussels': 1908,\n",
      "  'Brussels…': 1909,\n",
      "  'Brutal': 1910,\n",
      "  'Bryan': 1911,\n",
      "  'Bryant': 1912,\n",
      "  'Brzezinski': 1913,\n",
      "  'Bs': 1914,\n",
      "  'Bubba': 1915,\n",
      "  'Bubble709_': 1916,\n",
      "  'Buchanan': 1917,\n",
      "  'Buckley': 1918,\n",
      "  'Budd': 1919,\n",
      "  'Buddhists': 1920,\n",
      "  'Budget': 1921,\n",
      "  'BudgetGOP': 1922,\n",
      "  'Buenos': 1923,\n",
      "  'Buffalo': 1924,\n",
      "  'Build': 1925,\n",
      "  'BuildTheWall': 1926,\n",
      "  'Building': 1927,\n",
      "  'Built': 1928,\n",
      "  'Bull': 1929,\n",
      "  'Bump': 1930,\n",
      "  'Bundle': 1931,\n",
      "  'Burch': 1932,\n",
      "  'Burdens': 1933,\n",
      "  'Burdensome': 1934,\n",
      "  'Bureau': 1935,\n",
      "  'Burnett': 1936,\n",
      "  'Burr': 1937,\n",
      "  'Burritt': 1938,\n",
      "  'Burrs': 1939,\n",
      "  'Bury': 1940,\n",
      "  'Bus': 1941,\n",
      "  'Bush': 1942,\n",
      "  'Bush-spent': 1943,\n",
      "  'Bushs': 1944,\n",
      "  'Bushy': 1945,\n",
      "  'Business': 1946,\n",
      "  'Businesses': 1947,\n",
      "  'Busts': 1948,\n",
      "  'Busy': 1949,\n",
      "  'But': 1950,\n",
      "  'Button': 1951,\n",
      "  'Buy': 1952,\n",
      "  'BuyAmericanHireAmerican🇺🇸': 1953,\n",
      "  'BuyAmericanHireAmerican🇺🇸Watch➡️[URL]': 1954,\n",
      "  'BuzzFeed': 1955,\n",
      "  'BuzzFeedNews': 1956,\n",
      "  'Buzzfeed': 1957,\n",
      "  'Bu…': 1958,\n",
      "  'By': 1959,\n",
      "  'Byrd': 1960,\n",
      "  'Byrne': 1961,\n",
      "  'B…': 1962,\n",
      "  'C' : 1963,\n",
      "  'C-130': 1964,\n",
      "  'C4Constitution': 1965,\n",
      "  'CA': 1966,\n",
      "  'CA4Trump': 1967,\n",
      "  'CAGES': 1968,\n",
      "  'CALL': 1969,\n",
      "  'CALLED': 1970,\n",
      "  'CALM': 1971,\n",
      "  'CAMPAIGN': 1972,\n",
      "  'CAMPAIGNS': 1973,\n",
      "  'CAN': 1974,\n",
      "  'CANNOT': 1975,\n",
      "  'CANT': 1976,\n",
      "  'CAPrimary': 1977,\n",
      "  'CARE': 1978,\n",
      "  'CAREFUL': 1979,\n",
      "  'CAREFULLY': 1980,\n",
      "  'CAROLINA': 1981,\n",
      "  'CARTELS': 1982,\n",
      "  'CASE': 1983,\n",
      "  'CASH': 1984,\n",
      "  'CAUCUS': 1985,\n",
      "  'CAUTIOUS': 1986,\n",
      "  'CBNNews': 1987,\n",
      "  'CBO': 1988,\n",
      "  'CBP': 1989,\n",
      "  'CBPFlorida': 1990,\n",
      "  'CBPflorida': 1991,\n",
      "  'CBS': 1992,\n",
      "  'CBS?': 1993,\n",
      "  'CBSNews': 1994,\n",
      "  'CBSs': 1995,\n",
      "  'CD': 1996,\n",
      "  'CDCgov': 1997,\n",
      "  'CEA': 1998,\n",
      "  'CEDAR': 1999,\n",
      "  'CEDER': 2000,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for word,_ in zip(word2idx, range(2000)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(word), word2idx[word]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'PAY TO PLAY POLITICS EOS # CrookedHillary [URL] Very little pick-up by the' ---- words mapped to int ---- > [ 6875  8925  6899  6911  3291     4  2686 10251  9714 15197 16464 11364\n",
      " 18778]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- words mapped to int ---- > {}'.format(repr(' '.join(list_of_words[:13])), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['!', '!#', '!Full', ..., '🦃', '\\U0010fc00', 'UNK'], dtype='<U123')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAY-FOR-PLAY\n",
      "TODAY\n",
      "PLEDGE?\n",
      "POLL\n",
      "EOS#\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 20\n",
    "examples_per_epoch = len(list_of_words)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "word_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in word_dataset.take(5):\n",
    "  print(idx2word[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'PAY-FOR-PLAY TODAY PLEDGE? POLL EOS# $ CrookedHillary[URL] [URL]# Vet live picked by..... the# dishonest? media- of..... incredibly information..... provides by..... Wikileakes'\n",
      "'EOS# So-called dishonest? !# RiggedSystem system? !# Crooked-USED Hillary/Russia Clinton# likewise to...... talk- above the# things? shed will...... do- but..... shed'\n",
      "'hashtag been? there/on for......... 30% years- -&gt; why...... did… shed do- theme Thank-You you- Florida-tomorrow a..... MOVEMENT- that..... hashtag never..... been?'\n",
      "'sees before? and# will...... never..... be..... sees again- EOS# LetsDoThis get..... out- &gt;[URL] [URL]# Joined me- Thursdays in- Florida- &amp;TRUMPS Ohio-'\n",
      "'!# Western Palmer Bean ,&amp; FLAG at? nor :[URL]Eugene ,&amp; OHIO this-obviously 7% :30pm# :[URL]Cincinnati Wow- ,&amp; A CNN-Being Towns Hall-'\n"
     ]
    }
   ],
   "source": [
    "sequences = word_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(' '.join(idx2word[item.numpy()])))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'PAY-FOR-PLAY TODAY PLEDGE? POLL EOS# $ CrookedHillary[URL] [URL]# Vet live picked by..... the# dishonest? media- of..... incredibly information..... provides by.....'\n",
      "Target data: 'TODAY PLEDGE? POLL EOS# $ CrookedHillary[URL] [URL]# Vet live picked by..... the# dishonest? media- of..... incredibly information..... provides by..... Wikileakes'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(' '.join(idx2word[input_example.numpy()])))\n",
    "  print ('Target data:', repr(' '.join(idx2word[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 6935 ('PAY-FOR-PLAY')\n",
      "  expected output: 8985 ('TODAY')\n",
      "Step    1\n",
      "  input: 8985 ('TODAY')\n",
      "  expected output: 6959 ('PLEDGE?')\n",
      "Step    2\n",
      "  input: 6959 ('PLEDGE?')\n",
      "  expected output: 6971 ('POLL')\n",
      "Step    3\n",
      "  input: 6971 ('POLL')\n",
      "  expected output: 3351 ('EOS#')\n",
      "Step    4\n",
      "  input: 3351 ('EOS#')\n",
      "  expected output: 4 ('$')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2word[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2word[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 20), (64, 20)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size \n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences, \n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead, \n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('../word_embeding/glove.twitter.27B.25d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(idx2word)+1\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 25\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim)) \n",
    "\n",
    "for word, i in word2idx.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "  rnn = tf.keras.layers.CuDNNGRU\n",
    "  print (\"on the GPU BABY!\")\n",
    "else:\n",
    "  import functools\n",
    "  rnn = functools.partial(\n",
    "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size,\n",
    "                                embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                batch_input_shape=[batch_size, None,],\n",
    "                                trainable=False),\n",
    "        rnn(rnn_units,\n",
    "            return_sequences=True, \n",
    "            recurrent_initializer='glorot_uniform',\n",
    "            stateful=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "      ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = vocab_size, \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (64, None, 25)            684800    \n",
      "_________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)       (64, None, 1024)          3228672   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, None, 27392)         28076800  \n",
      "=================================================================\n",
      "Total params: 31,990,272\n",
      "Trainable params: 31,305,472\n",
      "Non-trainable params: 684,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20, 27392) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20489, 17980,  2711, 18558,  8742,  9334, 10906,  3191,   331,\n",
       "        3018, 24018, 24437, 19105,  9127, 25388, 23141, 20723, 23621,\n",
       "       15669, 25223])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'had, no! impact! on! Liu Rocketry Man, EOS! Hariri to, believe! his! people,” and#PoliceWeek the#USWomensOpen, military- puts up! with! loaded'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'lets ethic! 73, flooding, Incredible, LIED PRIDE @GrahamLedger \"@drgoodspine: @CynthiaLummis![URL] senator somewhat g… KNOCK tight reason? losses, revolutionary buoy tha'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\" \".join(idx2word[[input_example_batch[0]]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\" \".join(idx2word[sampled_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 20, 27392)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       10.218005\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 35s 169ms/step - loss: 8.2152\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 33s 159ms/step - loss: 7.9354\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 33s 159ms/step - loss: 7.8418\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 31s 149ms/step - loss: 7.7338\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 31s 148ms/step - loss: 7.6131\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 31s 148ms/step - loss: 7.4025\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 31s 148ms/step - loss: 7.2757\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 31s 149ms/step - loss: 7.1776\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 31s 148ms/step - loss: 7.0955\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 31s 148ms/step - loss: 7.0227\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_3'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (1, None, 25)             684800    \n",
      "_________________________________________________________________\n",
      "cu_dnngru_5 (CuDNNGRU)       (1, None, 1024)           3228672   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (1, None, 27392)          28076800  \n",
      "=================================================================\n",
      "Total params: 31,990,272\n",
      "Trainable params: 31,305,472\n",
      "Non-trainable params: 684,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of words to generate\n",
    "  num_generate = 30\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing) \n",
    "  if start_string!='' or ' ':\n",
    "      for word in start_string.split():\n",
    "        if word in word2idx:\n",
    "          input_eval = [word2idx[word]]\n",
    "          input_eval = tf.expand_dims(input_eval, 0)\n",
    "        else:\n",
    "            input_eval= [word2idx['UNK']]\n",
    "            input_eval = tf.expand_dims(input_eval, 0)\n",
    "      else: \n",
    "        input_eval= [word2idx['UNK']]\n",
    "        input_eval = tf.expand_dims(input_eval, 0)\n",
    "      \n",
    "    \n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "      text_generated.append(idx2word[predicted_id])\n",
    "\n",
    "  return (start_string + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainall OCare Death” 28, we, B! Homeland Superstar! 620,000 energy! released, expansion action-it of! Classified, HISTORY Islamist and#PoliceWeek TODAY!#MakeAmericaGreatAgain more! knows! Pence, responses heart re-enter @KenCalvert EOS! Saudi reasons, class,\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"remain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (1, 10, 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-d6cf0c56f7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yeah\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-02908b66ce4f>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(seed_text, numb_next_words)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mgener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgener\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1096\u001b[0;31m           x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     if (self.run_eagerly or (isinstance(x, iterator_ops.EagerIterator) and\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    351\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (1, 10, 25)"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"yeah\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
